\documentclass[a4wide]{report}

%\usepackage[latin1]{inputenc}
% \usepackage[francais]{babel}
\usepackage[T1]{fontenc}
\usepackage{fullpage}
\usepackage{eso-pic}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\usepackage{fancybox}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{makeidx}
\usepackage{mdwlist} % for compact lists
\usepackage{minitoc}

\usepackage[colorinlistoftodos]{todonotes}
\newcommand{\alaintodo}[1]{\todo[color=green!40,inline]{Todo: #1}}
\newcommand{\alaintodom}[1]{\todo[color=green!40]{\small #1}}
\newcommand{\warning}[1]{\todo[color=red!30,inline]{Warning: #1}}

\definecolor{rouge2}{RGB}{230,68,57}  % red S
\definecolor{orange}{RGB}{255,156,0}

\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\marmote}{\code{Marmote}}
\newcommand{\marmotecore}{\code{MarmoteCore}}
\newcommand{\marmotecorelegacy}{(legacy) \code{marmoteCore}}
\newcommand{\marmoteMC}{\code{MarmoteMarkovChain}}
\newcommand{\marmoteMDP}{\code{MarmoteMDP}}
\newcommand{\marmoteapplis}{\code{marmoteApplis}}
\newcommand{\marmoteball}{\code{marmotecore\_1.3.0.tgz}}
\newcommand{\marmoteappball}{\code{marmoteapplis\_1.3.0.tgz}}
\newcommand{\marmotepages}[1][]{\url{https://marmote.gitlabpages.inria.fr/marmote/#1}}
\newcommand{\mardir}{\code{MAR\_DIR}}
\newcommand{\alert}[1]{#1}
\newcommand{\xborne}{\code{Xborne}} % The "official" Xborne naming, if it exists!


\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

\title{\marmote\\ user manual}    
\author{Alain Jean-Marie}
\date{v1.2.0, \today}

\makeindex

\begin{document}        

\maketitle
\dominitoc

\newenvironment{textblock*}[1]{\begin{center}}{\end{center}}
\newenvironment{block}[1]{\fbox{#1}\fbox{}{}}
% \newenvironment{codeblock}[1]{\begin{verbatim}}{\end{verbatim}}

\section{Introduction}

\marmote\ is a C++ API for the construction and the analysis 
of Markov Chains.
It is an evolution of the \marmotecorelegacy\ API, itself
developed within the 
MARMOTE project (MARkovian MOdeling Tools and Environments)
funded by the Agence Nationale de la Recherche (France), 
number ANR-12-MONU-0019.

\bigskip

  %% Objectives:
  %% \begin{itemize}
  %% \item Develop Markov Enviromnent
  %% \item New solution and simulation techniques
  %% \item Application test-cases
  %% \end{itemize}

\begin{center}
  \vspace*{-4pt}%\hspace*{5cm}%\vspace*{2cm}
  \includegraphics[width=5cm]{Figures/DSC05143.jpeg}
  \begin{rotate}{90}\tiny Courtesy Laurent Chusseau\end{rotate}
\end{center}

The MARMOTE Software platform was developed with the intent
to provide to the general scientist a ``modeling environment''
which gives access to algorithms developed by specialists.
It is intended to be as open as possible, component-oriented,
and contributive.
% Will be populated with a modeling language, a minimal
% user interface, minimal solution algorithms.

\marmotecorelegacy\ was developed by Alain Jean-Marie, Issam Rabhi and Hlib Mykhailenko.

\marmote\ is currently developed by Alain Jean-Marie, Emmanuel Hyon and Patrick Brown.

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Markov chains, Markov modeling, Markov modelers}

% \subsection{Markov chains}

For the purposes of \marmote,
Markov chains (or Markov processes) are a class of stochastic processes
$X(t)$, $t\in \Z$ or $\R$

  \begin{itemize}
  \item evolving on a \alert{state space} $\mathcal{E}$
  \item described by a \alert{transition rule}
    \begin{align*}
      i \quad \longrightarrow \quad j
      &\qquad \text{with probability $p_{ij}$, for discrete-time Markov chains}
      \\
      i \quad \longrightarrow \quad j
      &\qquad \text{with rate $\lambda_{ij}$, for continuous-time Markov chains}
    \end{align*}
  \item from some \alert{initial state}.
  \end{itemize}

\noindent
The practical success of Markov chain as models for real-world situations
is due in part to the fact that many properties of Markov chains can be obtained
\begin{itemize}
\item by analyzing the \alert{graph} of transitions,
\item by solving problems of \alert{linear algebra}.
\end{itemize}


% \subsection{Markov modeling}
\smallskip\noindent
\textit{Markov modeling} consists in 
  \begin{itemize}
  \item constructing Markov models
  \item analyzing them:
    \begin{itemize}
    \item determine qualitive properties: structure, ergodicity, stability ...

    \item compute \alert{metrics} related with probabilities, frequencies,
      times, durations ...
    \end{itemize}
  \end{itemize}

At the risk of caricaturing somewhat,
the activities of a \textit{Markov modeler} can be classified
in two main ``profiles'':

\begin{description}
\item[Theoretician]: Aims at developing MC solution methods 
  \begin{itemize}
  \item as generic as possible
  \item yet taking into account the structure of the model
  \end{itemize}
  This activity involves:
  \begin{itemize}
  \item invent new formulas/algorithms
  \item program new methods
  \item test them on examples/benchmarks
  \item compare with previous methods (exec. time, accuracy)
  \end{itemize}

\item[Practician]: Develops Markov models for specific applications

  This activity involves:
  \begin{itemize}
  \item describe/represent model (parameters, structure, ...)

  \item test model with simulation

  \item solve model (analytic, numerical),
    loop until model passes tests

  \item execute experimental plans

  \item compare different models (e.g. simplifications)

  \end{itemize}
\end{description}

\marmote\ has the ambition to fit the needs of both categories.

\begin{comment}{MARMOTE Software base}

  Secondary objective: unify existing software

  The partners bring existing software packages
  \begin{itemize}
  \item Psi, Psi2, Psi3 (Perfect Simulation, INRIA/MESCAL)
  \item Xborne (Solutions with bounds for MC-related distributions, UVSQ/PRiSM)
  \item ERS (Basic MC solution)
  \end{itemize}
  
  Other software around
  \begin{itemize}
  \item PEPS
  \item GreatSPN
  \item Tangram II
  \item ...
  \end{itemize}
\end{comment}

\section{Architecture}

The general idea of the software is sketched in the following diagram.

\bigskip

\begin{center}

      \begin{tabular}{l|c|c|c|c|c|}
      \cline{2-6}
      SWM &
      \multicolumn{2}{|c|}{} & ... & Kepler & marmoteDTK \\
      \cline{2-6}
      Thematic \qquad &
      MarmoteQueue & MarmoteGame & ... & ...& \textcolor{purple}{\marmoteMDP} \\
      \cline{2-5}
      Generic \qquad &
      \multicolumn{4}{|c|}{\textcolor{purple}{\marmoteMC}} & \\
      \cline{2-6}
      Auxiliary \qquad &
      \makebox[1cm]{Psi} & \makebox[1cm]{Xborne} & R & \makebox[1cm]{...} & 
      \textcolor{purple}{\marmotecore}
      \\
      \cline{2-6}
      \end{tabular}

\end{center}
The purpose of \marmote\ is to provide the \textit{generic} API devoted to Markov Chains,
in the sub-package \marmoteMC.
The code for Markov chains itself is developed using objects provided by the \break
\marmotecore\ sub-package, or possibly external libraries or applications
(e.g. imported from Xborne or Psi), or methods of some programming language
(e.g. R, Python, Scilab/Matlab, etc.).

At higher levels, thematic libraries using Markov objects can be developed.
\marmoteMDP\ is a library devoted to Markov Decision Processes. It is described
in a separate document. As possible examples,
MarmoteQueue and MarmoteGame are fictitious libraries
which could exist one day, devoted to queueing theory and game theory models.

Ultimately, the libraries can be accessed either directly in applications,
or linked to Scientific Workflow Management systems such as Kepler.

\bigskip

\marmote\ is developped in \code{C++} in order to ease the resuse of legacy
\code{C}-style code. It offers naturally an API in \code{C++}. An API
in \code{Python} is currently under development.

\chapter{Installation}
\label{chap:installation}

This section provides instructions for installing the \marmotecore\ library
and compiling applications. These instructions, together with many
commented examples, are available at \marmotepages.

The recommended installation and compilation procedure is via \code{conda} and
\code{cmake}. Conventional installation via ``tarballs'' is possible for
some architectures, but not supported.

\section{Installing Anaconda/miniconda}

Before installing Marmote you will need to install \code{Anaconda} or \code{miniconda}
following instructions at \url{https://conda.io/miniconda.html}.

The command-line instructions are executed in a terminal window (linux and MacOS)
or in a ``anaconda prompt'' or a ``conda powershell'' (MS Windows).

\section{Preparing the \code{conda} environment}

The next step is to create the conda environment containing the
required conda packages, activate it and install the package.
This environment will be called \code{marmote-use}.
Installing the \texttt{marmote} package will also install the compatible
supporting libraries.
  \begin{quote}
\begin{verbatim}
$ conda create -n marmote-use
$ conda activate marmote-use
$ conda install -c marmote -c conda-forge marmote
\end{verbatim}
  \end{quote}

\section{Preparing a Marmote workspace}

Throughout these instructions, the directory \mardir\ is used as the
root directory. First create this directory and move into it:
  \begin{quote}
\begin{verbatim}
$ mkdir MAR_DIR
$ cd MAR_DIR
\end{verbatim}
  \end{quote}


\section{Compiling application examples}

Compiling an application using \marmote\ consists in 
creating a \code{cmake}. This simply requires placing the \code{C++} source files
and a \code{CMakeLists.txt} configuration file in some directory.
\footnote{Optionally, a separate directory can be created for each project.}

This process is explaned here using the illustrating examples
available at\\
\centerline{\marmotepages[cpp_examples.html].}

\subsection{Compilation of a single file}

First download the
\href{https://marmote.gitlabpages.inria.fr/marmote/_downloads/fabbd3cda731ce7630d9f292e6e577a2/example1.cpp}{source code}
and the \href{https://marmote.gitlabpages.inria.fr/marmote/_downloads/7fa58a554f941bd7fcf88c25fdf0f085/CMakeLists.txt}{configuration file}.

Next, execute:
  \begin{quote}
    \begin{verbatim}
$ mkdir build
$ cd build
$ cmake ..
$ make
\end{verbatim}
  \end{quote}
This produces the executable \code{example1}. To run the application:
\begin{quote}
\begin{verbatim}
$ ./example1 3 0.2 0.2 0.4
\end{verbatim}
\end{quote}

%% \subsection{Compilation of two project files at the same time}

%% First download the source files for
%% \href{https://marmote.gitlabpages.inria.fr/marmote/_downloads/bb6a9e85b58f9875e6ad627fc2ad7b9a/example1.cpp}{example \#1} and
%% \href{https://marmote.gitlabpages.inria.fr/marmote/_downloads/4c83ec70767e9835400667bd032b6e03/exampleMDP10.cpp}{example \#MDP10}, together with the
%% \href{https://marmote.gitlabpages.inria.fr/marmote/_downloads/fffebd0c64b67c740eb298c942a7cb68/CMakeLists.txt}{configuration file}.
%% Then execute:
%%   \begin{quote}
%%     \begin{verbatim}
%% $ mkdir build
%% $ cd build
%% $ cmake ..
%% $ make
%% \end{verbatim}
%%   \end{quote}
%% This produces two executables \code{example1} and \code{exampleMDP10}. 
%% To run the applications:
%% \begin{quote}
%% \begin{verbatim}
%% $ ./example1 3 0.2 0.2 0.6
%% $ ./exampleMDP10
%% \end{verbatim}
%% \end{quote}

\subsection{Compilation all examples}

First download the source files as a
\href{https://marmote.gitlabpages.inria.fr/marmote/_downloads/4c562e76c45ae6cd61dbaecfe23a3aa3/all_examples.zip}{zip archive},
together with the
\href{https://marmote.gitlabpages.inria.fr/marmote/_downloads/7fa58a554f941bd7fcf88c25fdf0f085/CMakeLists.txt}{configuration file}.
Unpack the source files:
  \begin{quote}
    \begin{verbatim}
$ unzip all_examples.zip
\end{verbatim}
  \end{quote}
Then execute:
  \begin{quote}
    \begin{verbatim}
$ mkdir build
$ cd build
$ cmake ..
$ make
\end{verbatim}
  \end{quote}
  This produces all executables \code{example1} to \code{example7}
  and \code{exampleMDP10} to \code{example40}.
To run the applications:
\begin{quote}
\begin{verbatim}
$ ./example1 3 0.2 0.2 0.6
$ ./example7
$ ./exampleMDP10
$ ./exampleMDP20
\end{verbatim}
\end{quote}

\begin{comment}
\subsection{Compiling a \marmotecore\ application}

The Makefiles provided in the \code{marmoteapplis} directory automate the
compilation process. The easiest way is to adapt them to your needs.

Users not familiar with \code{make} may use direct calls to the compiler
as follows. This command line assumes that the \marmotecore\ library has
been installed in directory \code{MAR\_DIR}, and that the application code
is in file \code{appli.cpp}.
\begin{quote}
\begin{verbatim}
g++ -IMAR_DIR/include appli.cpp -o appli -LMAR_DIR/lib -lMarmoteCore -lXborne -lpsi
\end{verbatim}
\end{quote}

\section{Installing supporting environments}

Some functionalities of \marmotecore\ use external programs that must
be installed separately.

\subsection{C++ libraries}

\subsection{R}
\label{sec:R}
\index{R!installation}

Some functionalities of \marmotecore\ are obtained using the popular 
\code{R} package. In order to take advantage of these, installing
the following software is needed.

\begin{enumerate}
\item install \code{R}, e.g. from the link \url{http://cran.r-project.org/}
  or through \code{yum/dcf}.
\item install the \code{Rcpp}: from inside \code{R}, issue
  the command \code{install.packages("Rcpp")}
\item then the package RInside with the command \code{install.packages("RInside")}
  \item then the package \code{markovchain} with the command \code{install.packages("markovchain")}.
\end{enumerate}

\subsection{Scilab}

\code{Scilab} is a scientific software comparable to \code{Matlab} but not
commercial. It is available from
\begin{center}
  \url{http://www.scilab.org/en}
\end{center}

\subsection{Xborne}
\label{sec:Xborne}
\index{Xborne!package}

\code{Xborne} is a suite of applications for creating, manipulating and
solving discrete-time Markov chains. It is available upon request
from Jean-Michel Fourneau: \code{Jean-Michel.Fourneau@uvsq.fr}.

\subsection{PSI}

\code{PSI3} is the environment for Event Modeling of Markov chains and
for Perfect Sampling. It is available from:
\begin{center}
  \url{http://psi.gforge.inria.fr/dokuwiki/}
\end{center}

\section{Running Marmote applications}

\marmotecore\ is designed so as to be able to benefit from the capabilities
of external programs.

\subsection{\code{R}}
\label{sec:R-environment}

Several methods use the \code{R} scientific computation environment
and its \code{markovchain} package.  In order to function,
\marmotecore\ must have been compiled with \code{R} enabled, and the
necessary \code{R} environment must be installed.

\subsection{\code{PSI}}

When running applications using \code{PSI1} functionalities, it is necessary
to add \code{MAR\_DIR/bin} in the environment variable \code{PATH}.

% \subsection{\code{Scilab}}

% TBD.

\end{comment}

\chapter{Programming with \marmote}
\label{chap:programming}

\section{Introduction}

Practical Markov modeling usually involves the following tasks:
\begin{description}
\item[{\bf create}] a Markov model, by specifying the state space and the transitions
\item[{\bf analyze}] the structure of the model, so as to detect
  qualitative properties and check that the model created is consistent with
  the model intended
\item[{\bf compute}] metrics associated with the model.
\end{description}


With \marmote, these tasks are performed through the creation of
objects in a \code{C++} program, and the execution of methods associated
with these objects.

\subsection{The Main Objects}

\marmote\ rests on 4 abstract, high-level classes:

\begin{itemize}
\item \code{MarmoteSet} for representing state spaces

\item \code{TransitionStructure} for representing transitions

\item \code{Distribution} for representing probability distributions

\item \code{MarkovChain} for representing Markov chains.

\end{itemize}

The classes \code{MarmoteSet}, \code{Distribution} and \code{TransitionStructure}
and their different instances are provided by the module \marmotecore.
The class \code{MarkovChain} and its different instances is provided in the module
\marmoteMC.

These main classes and their derived classes will be described in depth in
Chapter~\ref{chap:reference}. In the present chapter, we show through examples
how they are used.

\subsection{Constructing Markov Chains}

Creating an instance of \code{MarkovChain} objects can be done in 
one of three ways:

\begin{enumerate}
\item read the generator (and the state space) from a file
\item use a predefined class
\item create the generator ``by hand''.
\end{enumerate}

We describe these three ways below.

\subsubsection{Getting a Markov Chain from a file}

The following code shows three examples of creations of a
\code{MarkovChain} object by reading the model from one or several files:
\begin{quote}
\begin{verbatim}
      MarkovChain* c1 = new MarkovChain( "Xborne", NULL, 0, "rw1d" );
      MarkovChain* c2 = new MarkovChain( "PSI", NULL, 0, "rw1d" );
      MarkovChain* c3 = new MarkovChain( "Ers", NULL, 0, "rw1d" );
\end{verbatim}
\end{quote}

The name of the file is not directly specified. Instead, a model name is
supplied (here: \code{rw1d}) and a file format is specified (here:
\code{Xborne} or \code{PSI} or \code{Ers}).
\index{Xborne!input format}

The formats available are described in Appendix~\ref{chap:formats},
p.~\pageref{chap:formats}.
See also~\ref{sec:MarkovChain-I/O}.


\subsubsection{Using existing Markov chains}

\marmotecore\ provides Markov models of several important families
identified in the literature. See Appendix~\ref{chap:zoo},
p.~\pageref{chap:zoo}.

Currently implemented (a small part of the Markov Zoo):
\code{TwoStateContinuous} and \code{TwoStateDiscrete}, the two-state Markov chains
in continuous and discrete time,
\code{Homogeneous1DRandomWalk}, \code{Homogene\-ousMul\-tidRandomWalk},
\code{Homogeneous1DBirthDeath} and \code{HomogeneousMul\-tidBirthDeath},
models of random walks, in continuous or discrete time,
\code{PoissonProcess} and \code{MMPP}, models of arrival processes in continuous time,
and \code{Felsenstein81}, a model for BioInformatics.

The following code shows how these models are used.
\begin{quote}
\begin{verbatim}
      double pro[4] = { 0.1, 0.2, 0.3, 0.4 };
      Felsenstein81* c1 = new Felsenstein81( pro, 10.0 );

      Homogeneous1DRandomWalk* c3 = new Homogeneous1DRandomWalk( 10, 0.4, 0.3 );
\end{verbatim}
\end{quote}
The constructor of the \code{Felsenstein81} object needs an array of
probabilities \code{pro}. The constructor for \code{Homogeneous1DRandomWalk}
just needs a size parameter and two transition probabilities. See respectively
\S\ref{sec:Felsenstein81} and \S\ref{sec:homogeneous1DRandomWalk}.


% \subsubsection{Creating a Markov model by hand}

% This more complex process is described in the following section.

\subsubsection{Making a Markov chain}
\label{sec:making-Markov}

Creating a complex Markov chain is typically done in three steps:
\begin{enumerate}
\item create a \code{MarmoteSet} object, containing the state space
  representation
\item create a \code{TransitionStructure} object with the transitions
  characterizing the model,
\item create the Markov chain from this object.
\end{enumerate}
The first step is optional if the state space is simple enough.

A typical example of creation code following this pattern is:
\begin{quote}
\begin{verbatim}
      LayeredStateSpace* sp = new LayeredStateSpace( N, E1, E2, M, nu );
      SparseMatrix* gen = MakeGenerator( sp, N, E1, E2, M, nu );
      MarkovChain* myMC = new MarkovChain( gen ); 
\end{verbatim}
\end{quote}

In this example, \code{SparseMatrix} is a class deriving from
\code{TransitionStructure}, provided by \marmotecore. The user has
created a class \code{LayeredStateSpace} which inherits from
\code{MarmoteSet}. Its construction depends on the model parameters
\code{N}, \code{E1}, \code{E2}, \code{M} and \code{nu}.
The user has also programmed a procedure \code{MakeGenerator} to
actually perform the construction.

The code of this method uses the object of type \code{MarmoteSet}
with the following pattern:

\begin{quote}
\begin{verbatim}
    SparseMatrix* MakeGenerator(LayeredStateSpace* sp, ... ) {
    
      SparseMatrix* gen = new SparseMatrix( sp->Cardinal() );
    
      int stateBuffer[5];  // the state space has 5 dimensions
      sp->FirstState(stateBuffer);

      int idx = 0;
      do {
        ...
        // destination state stored in nextBuffer
        nextBuffer[0] = MIN( stateBuffer[0] + 1, someBound );
        ...
        gen->addToEntry( idx, sp->Index(nextBuffer), someRate );
        gen->addToEntry( idx, idx, -someRate );
        ...
       
        sp->NextState( stateBuffer );
        idx++;
      } while (!sp->IsFirst(stateBuffer));
      ...
      return gen;
    }   
\end{verbatim}
\end{quote}

In this procedure, the states of the state space are enumerated in
sequence, using the three constructs:
\begin{description}
\item[initialization] with \code{sp->FirstState(stateBuffer)}, which sets
  the state (represented in the array \code{stateBuffer} to the ``first''
  state of the state space;
\item[increment] of the state with \code{sp->NextState(stateBuffer)}, which
  moves the state to the next one in the enumeration order;
\item[termination test] with \code{sp->IsFirst(stateBuffer)} which tests
  whether the enumeration came back to the initial state.
\end{description}

Inside the loop, the current state is modified by the different events to
be considered. The result is stored in the variable \code{nextBuffer}.
The rates/probabilities associated with the transition are then added
to the generator being constructed with the instruction
\code{gen->addToEntry()}. The index of the destination state is
obtained from the state buffer with the fourth construct:
\code{sp->Index(nextBuffer)}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Computing on Markov Chains}

Many solution methods are available for \code{MarkovChain} objects
and derived classes.

% \subsubsection{An example}

In the following example, we show a 
comparison of computations for the stationary distribution:

\begin{quote}
\begin{verbatim}
  // use of specific methods for F81
  Felsenstein81* c1 = new Felsenstein81(...);
  Distribution* d1 = c1->StationaryDistribution();
  Distribution* d2 = c1->SimulateChain(...)->distribution();
  // comparison
  cout << "Distance L1(d1,d2) = " << d1->distanceL1(d2) << endl;
  // use of generic methods for MCs
  MarkovChain* c2 = static_cast<MarkovChain*>(c1);
  Distribution* d3 = c2->StationaryDistribution_GaussSeidel();
  Distribution* d4 = c2->StationaryDistribution_PowerMethod();
  Distribution* d5 = c2->StationaryDistribution_Xborne_LowBound();
  Distribution* d6 = c2->StationaryDistributionSample(...);
  Distribution* d7 = c2->SimulateChain(...)->distribution();
  Distribution* d8 = c2->SimulateChain2(...)->distribution();
\end{verbatim}
\end{quote}
In the first part of the code, an object of class \code{Felsenstein81} is
created, and two solution methods are used: first \code{StationaryDistribution()}
then \code{SimulateChain()}. The first one computes exactly the stationary
distribution, whereas the second one performs Monte Carlo simulation and
returns, in particular, an empirical distribution. The distance between
the two distributions is evaluated.

In the second part of the code, the \code{Felsenstein81} object is \textit{cast}
to a higer-level \code{MarkovChain} object, which has more solution methods.

\chapter{\marmote\ reference}
\label{chap:reference}

\minitoc

We describe in this chapter the four main classes of \code{marmote}
and their derived classes. We present the general interface of these
top-level classes. For derived classes, we describe when the general
interface has been re-implemented, and when specific methods have
been introduced.

As a general rule, attributes of \code{marmote}'s objects are
private and can be accessed (read or write) only through specific
``accessor/mutator'' methods.

\section{Basic types and constants}
\label{sec:basic-types}

\marmote\ uses a few numeric and symbolic types.
While using standard type like \code{int} or \code{long int} will work most of the
time, it is advised to conform to this type convention.

\begin{description}
\item[timeType]: describing whether the time model of the Markov Chain is discrete
  or contiuous; may be either of \code{DISCRETE}, \code{CONTINUOUS},
  \code{UNDEFINED}, \code{UNKNOWN}.
  \index{timeType@\code{timeType}}
  \index{types!time}

\item[stateType]: the integer type used for state indices in state spaces.
  It may be negative since practical modeling sometime uses negative indices.
  It is currently implemented
  as \code{long long int} but it is discouraged to rely on this assumption.
  \index{timeType@\code{stateType}}
  \index{types!state indices}

\item[cardinalType]: the integer type used for the cardinal of state spaces.
  It may \textit{not} be negative.
  It is currently implemented
  as \code{unsigned long long int} but it is discouraged to rely on this assumption.
  \index{timeType@\code{cardinalType}}
  \index{types!set cardinals}

\item[cacheType]: related to Monte-Carlo simulation of Markov Chains
  (see Section~\ref{sec:simulation}). May be either of \code{CACHE\_FULL}, \code{CACHE\_BASIC}
  and \code{CACHE\_NONE}. 
  \index{cacheType@\code{cacheType}}
  \index{types!simulation cache}

\item[simLenType]: related to Monte-Carlo simulation of Markov Chains
  (see Section~\ref{sec:simulation}). It is currently implemented as
  \code{unsigned long int} but it is discouraged to rely on this assumption.
  \index{simLenType@\code{simLenType}}
  \index{types!simulation length}

\item[inoutFormat]: formats of representation of objects in files for input/output.
  Some formats apply specifically to matrices or vectors or sets, others apply to
  several object types.
  \index{inoutFormat@\code{inoutFormat}}
  \index{formats, input/output}
  \begin{description}
\item[\code{FORMAT\_NONE}]:           Unspecified format
\item[\code{FORMAT\_MARMOTE}]:        Marmote format, also known as ``ERS'' format,
  described in Appendix~\ref{sec:Ers-specification}; applies to all objects
\item[\code{FORMAT\_MATLAB\_FULL},\code{FORMAT\_MATLAB\_SPARSE}]: Matlab formats for matrices; apply to transition structures
\item[\code{FORMAT\_SCILAB\_FULL},\code{FORMAT\_SCILAB\_SPARSE}]: Scilab formats for matrice, described
  in Appendix~\ref{sec:Scilab-format}; apply to transition structures
\item[\code{FORMAT\_MATRIXMARKET\_SPARSE}, \code{FORMAT\_MATRIXMARKET\_FULL}]: MatrixMarket formats for matrices; apply to transition structures
\item[\code{FORMAT\_MAPLE}]:          Maple format with full matrices; applies to transition structures and some distributions
\item[\code{FORMAT\_R}]:              Matrix format for the \code{R} environment, described
  in Appendix~\ref{sec:R-format}; applies to transition structures
\item[\code{FORMAT\_NUMPY}]:          Python format with full matrices; applies to transition structures
\item[\code{FORMAT\_MARCA}]:          Format for the \code{MARCA} software, described in Appendix~\ref{sec:MARCA}
\item[\code{FORMAT\_MARMOTE\_FULL}]:  Marmote format with full matrices; applies to transition structures
\item[\code{FORMAT\_MATH}]:           Mathematical notation format; applies to some distributions
\item[\code{FORMAT\_PSI3}]:           Psi3 yaml format; applies to transition structures
\item[\code{FORMAT\_XBORNE\_CII}, \code{FORMAT\_XBORNE\_CUU}, \code{FORMAT\_XBORNE\_RII}]: Xborne formats for matrices,
 described in Appendix~\ref{sec:Xborne-format}; apply to transition structures
\item[\code{FORMAT\_XBORNE\_SIZE}]:   Xborne format for the matrix size specification ".sz"; applies to transition 
structures
\item[\code{FORMAT\_FLAT}]:           Flat format for sets
\item[\code{FORMAT\_STRUCTURED}]:     Structured format for sets
\item[\code{FORMAT\_XBORNE\_SET}]:    Xborne format for set files ".cd", described in  Appendix~\ref{sec:Xborne-format}
\end{description}
  The default format is usually \code{FORMAT\_MARMOTE}.

\item[stateWriteType]: relates to printing states and state spaces.
  Available types are:
  \begin{description}
  \item[\code{STATE\_INDEX}] only the index of the state is written
  \item[\code{STATE\_FULL}] the full representation of the state is written
  \item[\code{STATE\_BOTH}] both the index and the representation state are written.
  \end{description}
  
\end{description}


\section{System-wide features}

Some features are common to all objects, and some instructions have an effect
on all operations in the system.

Common methods for all \marmote\ objects are:
\begin{description}
\item[\code{className(void)}] returns the C++ class name of the object,
\item[\code{toString(void)}] returns in principle a complete description of the object
\item[\code{info(void)}] returns a synthetic information about the object;
\end{description}

The behavior of the system can be controlled via calls to ``policy'' methods:
\begin{description}
  \item[in/out formats] is controlled with
\code{setInoutFormatPolicy(inoutFormat io\_format)}
and queried with
\code{inoutFormat inoutFormatPolicy(void)}; see Section~\ref{sec:basic-types}
for a list of formats and their effects;
its default value is \code{FORMAT\_MARMOTE};

\item[Pyton/numpy interface] is controlled with 
\code{ void setNumpyPrefix(std::string prefix)}
and queried with
\code{ std::string numpyPrefix(void)}; the prefix is used when formatting output
with \code{FORMAT\_NUMPY}, e.g. \code{np.array(...)};
its default value is \code{np};

\item[state space appearance] % when printing states and state spaces
  is controlled
  with \code{ void setStateWritePolicy(stateWriteType state\_format)}
  and queried with \code{ stateWriteType stateWritePolicy(void)};
  see Section~\ref{sec:basic-types} for a list of types and their effects;
  its default value is \code{STATE\_INDEX};

  \item[numerical precision] in algorithms is controlled with
\code{ void setPrecision(double epsilon)}
and queried with
\code{ double precision(void)}; its default value is $10^{-7}$;

\item[number of iterations] in iterative algorithms is controlled with
\code{ void setMaxIter(unsigned int iter)}
and queried with
\code{ unsigned int maxIter(void)}; its default value is 2000.

\end{description}

\section{The \code{MarkovChain} object}
\label{sec:MarkovChain}
\index{MarkovChain@\code{MarkovChain}!reference}

\subsection{Common features}

The methods common to \code{MarkovChain} and derived classes are
summarized in the following tables, grouped by functionalities.

\subsubsection{Definition}

This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include <marmoteMarkovChain/marmoteMarkovChain.h>
\end{verbatim}
\end{quote}

\subsubsection{Attributes and accessors}

\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
  timeType & 		type\_ & \rm time type: discrete or continuous \\
  stateType &		state\_space\_size\_ & \rm size of the state space \\
  MarmoteSet* &         state\_space\_ & \rm the state space \\
  TransitionStructure* & generator\_ & \rm transition structure of the chain \\
  DiscreteDistribution* & init\_distribution\_ & \rm initial distribution of the process
  \\
  string & model\_name\_ & \rm name of the model \\
  string & format\_ & \rm representation format for the model \\
    \hline
  \end{tabular}
\end{center}

The ``size'' of the state space is the number of states it contains.
It coincides with the size of the \code{MarmoteSet} object which
represents the state space.

The generator is supposed to describe the transition structure of the model.
It may however be left to \code{null} in certain models where the transition
structure is implicit.

The initial distribution is used for Monte Carlo simulations. If not set,
the Dirac distribution at the state numbered 0 is used by default.
It is however advised to set this variable.

The model name and its ``format'' are usually deduced when the object is
created by reading it from a file. See below.

\begin{center}
  \small\tt
  \begin{tabular}{lll}
    \hline
    timeType & type() & \rm get the time type of the model \\
    stateType & state\_space\_size() & \rm get the size of the model \\
    TransitionStructure* & generator() & \rm get the generator \\
    void & set\_init\_distribution(DiscreteDistribution* d) & \rm provide the
    initial distribution \\
    void & set\_generator( TransitionStructure* tr ) & \rm provide the generator \\
    void & set\_format(string format) & \rm set the representation format \\
    void & set\_model\_name(string modelName) & \rm set the model name \\
    string & model\_name() & \rm get the model name \\
    string & format() & \rm get the format \\
  \hline
\end{tabular}
\end{center}

Note that there is currently no accessor for the variable \code{state\_space\_}.
It is not possible either to modify the time type after creation. 

\subsubsection{Constuctors}
\label{sec:MarkovChain-I/O}

The class provides three constructors:\footnote{Plus a \code{Copy()} method.}
\begin{quote}
\begin{verbatim}
      MarkovChain(stateType sz, timeType t);
      MarkovChain(TransitionStructure* tr);
      MarkovChain(string format, string param[], int nbParam, string model_name );
\end{verbatim}
\end{quote}

The constructor \code{MarkovChain(stateType sz, timeType t);} creates a Markov chain
object over a state space of size \code{sz} and with type given by \code{t}.
The space type (\code{stateType}) is an integer, see Section~\ref{sec:basic-types}.
The time type can be \code{DISCRETE} or \code{CONTINUOUS}.
\index{timeType@\code{timeType}} \index{types!time}
The state space is implicitly a \code{MarmoteInterval} object.

The construction of the transition structure is left to the user.

In the constructor \code{MarkovChain(TransitionStructure* tr)}, the transition
structure is provided. The size of the state space is deduced from it.

The third version creates a \code{MarkovChain} object by reading from one or
several files. The parameter \code{format} specifies the format or language
in which the model is specified.
Formats available are: ERS, PSI1/MARCA and XBORNE.
% Ers, PSI, MARCA, XBORNE (Xborne/Rii), XBORNEPres (Xborne/C).
\index{Xborne!input format}
\index{MARCA!input format}
See Appendix~\ref{chap:formats} for a
description of these formats. Depending on this format, one or several
file names or extensions must be provided. Those are listed in the \code{param}
array, the size of which is defined by \code{nbParam}.
The parameter \code{model\_name} serves as a common prefix for file names.

When a problem occurs during the construction (\textit{e.g.} a file is not present,
or when its parsing fails...), a functional
\code{MarkovChain} object is returned, but with an zero-sized state space
and an empty generator.

\subsubsection{Pseudo-constructor}

A fourth way to create Markov chain objects is to use the class (static)
method:

\begin{quote}
\begin{verbatim}
      RandomMarkovChain(int multipleOfPeriod, stateType nStates);
\end{verbatim}
\end{quote}

This creates randomly a Markov Chain with a specific
periodicity given by $d=$\code{multipleOfPeriod} and \code{nStates}
states. The number of states is actually always a multiple of $d$: $d
\times \lfloor \code{nStates}/d \rfloor$.

\subsubsection{Structural analysis}

Methods are provided to perform a structural analysis of the Markov chain
(in fact, of its transition structure). They come in two groups:

\begin{center}
  \small\tt
  \begin{tabular}{lll}
    \hline
  std::vector<cardinalType> & AbsorbingStates() & \rm find the states that are absorbing \\
  std::vector<std::vector<cardinalType>\,> & RecurrentClasses() &
  \rm computes recurrent classes \\
  std::vector<std::vector<cardinalType>\,> & CommunicatingClasses() &
  \rm computes communicating classes \\
  bool & IsIrreducible() & \rm checks whether the chain is irreducible \\
  bool & IsAccessible(stateType from, & \rm checks whether a path \\
  & \qquad\qquad\qquad\  stateType to) & \rm exists between two states \\
  stateType & Period() & \rm computes the periodicity \\
  std::vector<MarkovChain*>* & SubChains() & \rm computes the decomposition \\
  & & \rm in irreducible subchains \\
    \hline
  \end{tabular}
\end{center}

\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
  std::vector<int> & AbsorbingStatesR() & \rm find the states that are absorbing \\
  std::vector<std::vector<int>\,> & RecurrentClassesR() &
  \rm computes recurrent classes \\
  std::vector<std::vector<int>\,> & CommunicatingClassesR() &
  \rm computes communicating classes \\
  bool & IsIrreducibleR() & \rm checks whether the chain is irreducible \\
  bool & IsAccessibleR(int from, & \rm checks whether a path \\
  & \qquad\qquad\qquad\ \ int to) & \rm exists between two states \\
    \hline
  \end{tabular}
\end{center}
The first group depends on the BFS exploration methods developed within
\marmotecore. The second group is an interface to the methods of the
\code{markovchain} package of \code{R}.
This feature is not available in the current version.
% See Section~\ref{sec:R-environment}.
% \index{markovchain package (R)!structural analysis}
% \index{R!markovchain package}

These methods refer to the notion of \textit{communication} in Markov chains:
the existence of a path that goes from one state to another.
The method \code{IsAccessible()} checks this for given pairs of nodes.

The ``classes'' are equivalence classes for the communication
relationship.  Those are computed by the method
\code{CommunicatingClasses()}.
Among the classes, some are \textit{recurrent}. Those are computed
by \\
\code{RecurrentClasses()}. Both methods return a list of classes
(using the \code{vector} template of \code{C++}'s Standard Template Library)
each class being itself a list of nodes.
\index{class (communicating)!definition}
\index{class (communicating)!recurrent}

Absorbing states are those for which $T_{i,i} = 1$ in discrete time
or $T_{i,i} = 0$ in continuous time. They are computed by
\code{AbsorbingStates()} and returned as a list of nodes.

\subsubsection{Monte Carlo Simulation (forward)}
\label{sec:simulation}
\index{Monte Carlo simulation}

Monte Carlo simulation consists in generating a trajectory of the Markov chain
model using (pseudo-)random numbers.
The standard methods uses the data from the chain's generator to sample
transitions from one state to the next one.
Details vary slightly according to the time type of the chain.

The generic interface for Monte Carlo simulation is:
\begin{center}
  \small\tt
  \begin{tabular}{lll}
    \hline
    SimulationResult* & SimulateChain(double t, bool stats, bool traj, bool incr, bool trace) & \\
    SimulationResult* & SimulateChainDT(long t, bool stats, bool traj, bool trace) & \\
    SimulationResult* & SimulateChainCT(double t, bool stats, bool traj, bool incr, bool trace) & \\
    SimulationResult* & SimulateChainCT\_AllOpt(double t, bool stats, bool traj, bool incr, \\
    & \phantom{SimulateChainCTAllOpt\quad}
    bool trace, bool fullState, cacheType ctype ) & \\
    SimulationResult* & SimulateChainDT\_AllOpt(long t, bool stats, bool traj, & \\
    & \phantom{SimulateChainDTAllOpt\quad}
    bool trace, bool fullState, cacheType ctype ) & \\
    SimulationResult* & SimulatePSI(long t, bool stats, bool traj, bool trace) & \\
    SimulationResult* & SimulateChainR( double t,
    bool stats, bool traj, bool trace );
    \\
    \hline
  \end{tabular}
\end{center}

The methods \code{SimulateChainDT} and \code{SimulateChainDT\_AllOpt} are specific
to discrete-time Markov chains.
Similarly, method \code{SimulateChainCT} and \code{SimulateChainCT\_AllOpt} are
specific to continuous-time Markov chains. The method \code{SimulateChain} is the
general entry point: it detects the type of the chain and uses one of
\code{SimulateChainCT} or \code{SimulateChainDT} to perform the simulation.
The method \code{SimulateChainR} is an interface to the simulation procedure
for discrete-time chains in the \code{R} package \code{markovchain}.
\index{markovchain package (R)!Monte-Carlo simulation}

\paragraph{Input Parameters.}
Four parameters are common to all methods:
\begin{description}
\item[\code{t}]: the maximal time up to which the trajectory should be
  simulated. For discrete-time chains, this is an integer number
  and it also represents the number of steps to be simulated.
  For continuous-time chains, the trajectory is simulated up to this
  value, which may involve an arbitrary number of transitions.
\item[\code{stats}]: a flag specifying whether statistics must be
  collected along the way. The standard statistic\footnote{This behavior
    may be modified in the implementation of these methods in derived
    classes.} is to collect empirical state probabilities.
\item[\code{traj}]: a flag specifying whether the trajectory should be
  stored during the simulation. Storing trajectories may require
  substantial amounts of memory and may not be useful if statistics are
  collected and/or the trajectory is printed along the way.
\item[\code{trace}]: a flag specifying whether the trajectory should
  be printed (to the standard output) along the way. Printing trajectories
  may slow down the execution of the simulation, but may save memory
  and offload the burden of statistics to another application.
\end{description}

\noindent
The fifth parameter is specific to continuous-time simulations:
\begin{description}
\item[\code{incr}]: a flag specifying whether the time increments between
  transitions should be collected, and printed along the trajectory if
  the \code{trace} flag is set.
\end{description}

\noindent
Two more parameters are specific to 
methods \code{SimulateChainDT\_AllOpt} and \code{SimulateChainCT\_AllOpt},
which allow a finer control on the simulation and its output:
\begin{description}
\item[\code{fullState}]: a flag specifying whether the complete representation
  of the state should be printed when \code{trace} is active; when set,
  the method \code{PrintState()} of the state space (see Section~\ref{sec:MarmoteSet})
  is called after the index of the state is printed;

\item[\code{cacheType}]: controls the way transition distributions are stored
  during the simulation. The possibilities are \code{CACHE\_FULL}, \code{CACHE\_BASIC}
  and \code{CACHE\_NONE}. Under \code{CACHE\_FULL} (which is the default for
  simulations), all transitions are stored. This saves times when states are
  visited several times, but is impractical for large state spaces, and impossible
  for infinite state spaces. Under \code{CACHE\_BASIC}, the two last transitions
  are kept in cache. Under \code{CACHE\_NONE}, transition distributions are
  computed every time.
  \index{cacheType@\code{cacheType}}
  \index{types!simulation cache}
\end{description}

\paragraph{Output.}
\index{simulation result@\code{SimulationResult}}
Simulation results are stored in a versatile specific object:
\code{SimulationResult}. The attributes of a \code{SimulationResult}
object are:
\begin{center}
  \small\tt
  \begin{tabular}{lll}
    \hline
    timeType	& type\_ & \rm type of the Markov chain / trajectory \\
    MarmoteSet* & state\_space\_ & \rm state space of the samples \\
  cardinalType	& state\_space\_size\_ & \rm size of the state space \\
  simLenType	& trajectory\_size\_ & \rm number of transitions in the trajectory \\
  bool		& has\_distrib\_ & \rm flag corresponding to parameters \code{*\_cumTime\_} \\
  bool		& has\_trajectory\_ & \rm flag corresponding to parameters \code{*\_dates\_} \\
  bool		& has\_increments\_; & \rm flag corresponding to parameter \code{increments\_} \\
  bool		& trace\_; & \rm indicator of whether trajectory is traced \\
  std::vector<double>	  & CT\_dates\_;    & \rm table of times in the trajectory \\
  std::vector<simLenType> & DT\_dates\_;    & \rm table of times in the trajectory \\
  std::vector<double>	  & increments\_;   & \rm table of time increments in the trajectory \\
  std::vector<cardinalType> & state\_idx\_; & \rm table of states in the trajectory \\
  cardinalType            & max\_state\_;   & \rm maximal state reached, in case of infinite state space \\
  std::vector<simLenType> & DT\_cumTime\_;  & \rm table of cumulated times in states for discrete time \\
  std::vector<double>     & CT\_cumTime\_;  & \rm table of cumulated times in states for continuous time \\
  cardinalType            & last\_state\_;  & \rm state of last record \\
  double                  & last\_time\_;   & \rm time of last record, in continuous-time \\
  std::ostream*           & out\_;          & \rm stream to which tracing is sent \\
  bool                    & fullstate\_;    & \rm indicates whether the indices should be expanded into states \\
  \hline
  \end{tabular}
\end{center}

Interface: methods from \code{SimulationResult}
\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
    \multicolumn{3}{l}{// constructors} \\
    & SimulationResult(int size, timeType t, bool stats) & \\
    & SimulationResult(string format, string modelName, bool stats) & \\
    \multicolumn{3}{l}{// accessors } \\
    void & setTrajectory(bool v) & \\
    void & setTrajectorySize(int l) & \\
    void & setTrajectory(double* d, int *s) & \\
    void & setDistribution(DiscreteDistribution *d) & \\
    DiscreteDistribution* & distribution() & \\
    int & trajectorySize() & \\
    vector<double>* & CT\_dates() & \\
    vector<simLenType>* & DT\_dates() & \\
    vector<cardinalType>* & states() & \\
    void & recordCTSample( double date, cardinalType state ) & \\
    void & recordDTSample( simLenType date, cardinalType state ) & \\
    \multicolumn{3}{l}{// I/O } \\
    void & writeTrajectory( ostream* out, string format ) & \\
    \hline
  \end{tabular}
\end{center}

The methods \code{dates()} and \code{states()} give access to the trajectory,
the total size of which is obtained with \code{trajectorySize()}.
The statistics that are collected are returned as a distribution object
with \code{distribution()}.

\paragraph{Initial distribution.} The simulation must start from some
initial state. This state is obtained by sampling from the
\code{initial\_distribution\_} attribute of the Markov chain.
This value can be set with the method \code{set\_init\_distribution()}.
If not set, the distribution \code{DiracDistribution(0)} is used.
\index{initial distribution}

\paragraph{Random number generation.}
\index{Random Number Generator}
There is currently no way to interact with the Random Number Generator
that is used in sampling distributions and performing Monte Carlo simulation.


\subsubsection{Exact sampling from the stationary distribution (backwards)}

\index{exact sampling}
\index{perfect sampling}
\textit{Exact Sampling} consists in drawing directly samples from the
stationary distribution of a Markov chain. This applies to discrete-time
Markov chains (and continuous-time ones after uniformization) and
can be done with the ``backwards coupling'' technique.

\marmotecore\ supplies a method implementing this technique for general
chains. It uses the implementation from the \code{PSI-1} package,
see \url{http://psi.gforge.inria.fr/dokuwiki/}.

Usage:
\begin{quote}
\begin{verbatim}
      SimulationResult* StationaryDistributionSample (int nbSamples);
\end{verbatim}
\end{quote}

In that case, the attributes of the \code{SimulationResult} object that
is returned, have a signification that differs from the one in
``Monte Carlo'' methods.

The \code{\_states} attribute (which is accessed through the
\code{states()} method contains the list of samples that were
obtained. The \code{\_dates()} attribute (accessed through
\code{dates()}) contains the backward coupling time that was necessary
for each sample.  The size of both these arrays is equal to the value
of the parameter \code{nbSamples} of the
\code{StationaryDistributionSample()} method.

This method uses three external programs: \code{psi\_alias},
\code{psi\_traj} and \code{psi\_sample}. These should be accessible
through the \code{\$PATH} environment variable.

\subsubsection{Computation of the stationary distribution}
\label{sec:MarkovChain-stationary}
\index{stationary distribution}

Several methods are provided for computing (usually: numerically
approximating) the stationary distribution of Markov chains.
There are methods with few controls, supposedly easy to use:
\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
          Distribution* & StationaryDistribution(bool progress) & \\ 
          Distribution* & StationaryDistributionCT(bool progress) & \\
          Distribution* & StationaryDistributionDT(bool progress) & \\ 
          Distribution* & StationaryDistributionGthLD() & \\ 
          Distribution* & StationaryDistributionSOR() & \\
          Distribution* & StationaryDistributionR() & \\
          \hline
  \end{tabular}
\end{center}
and one entry point with detailed controls for iterative methods:
\begin{quote}
\begin{verbatim}
Distribution* StationaryDistributionIterative( 
                              string method, 
                              int tmax, 
                              double precision, 
                              string initDistribType, 
                              DiscreteDistribution* iDis,
                              bool progress ).
\end{verbatim}
\end{quote}

\paragraph{Linear Algebra methods.}
The methods \code{StationaryDistributionGthLD()} and
\code{StationaryDistributionR()} use algorithms for solving the
linear system
\begin{displaymath}
  \pi T = 0 \quad \text{(continuous time), or}
  \qquad
  \pi T = \pi \quad \text{(discrete time)}
\end{displaymath}
together with the constraint that $\pi$ is a probability vector.
They are exact, up to numerical errors.
They use an amount of memory proportional to the size of a full
matrix and may not be suited for large problems.

The method \code{StationaryDistributionGthLD()} performs a call
to the corresponding application from \code{Xborne}.
This feature is not available in the current version.
% See Section \ref{sec:Xborne}.

The method \code{StationaryDistributionR()} uses the \code{R}
environment.
This feature is not available in the current version.
% See Section \ref{sec:R-environment}.

\paragraph{Standard Iterative methods.}
The remaining methods are iterative in the sense that they build
a sequence of vectors $\pi_0, \pi_1, \ldots, \pi_n, \ldots$ that
ideally converges to the solution $\pi$. Usually, these methods
have several control parameters. These parameters are fixed to
some default values in the convenient methods
\code{StationaryDistribution()},
\code{StationaryDistributionCT()},
\code{StationaryDistributionDT()}
and
\code{StationaryDistributionSOR()}.
The first one is actually a common entry point that selects
one of the two following ones depending on the type of the Markov chain.

For cases where a finer control is needed, 
the method \code{StationaryDistributionIterative()} is provided
with all parameters. It currently supports two algorithms (specified in
the \code{method} variable): \code{"Power"} and \code{"Embed"}.
\index{stationary distribution!power method}
\index{stationary distribution!embedding method}
The first algorithm is the standard Power method on probability
transition matrices. It is applied to the uniformized chain in
the case of continuous-time. The second algorithm is specific of
continuous-time. It applies the power method to the discrete-time
Markov chain embedded at jump times, then corrects the distribution
obtained so as to provide the stationary distribution. 

Alternately, a direct call to the corresponding methods can be done
with the interface:
\begin{quote}
\begin{verbatim}
Distribution* StationaryDistributionCTEmbedding(int tMax, double precision,
                                          DiscreteDistribution *iDis, bool progress );
Distribution* StationaryDistributionPower(int tMax, double precision,
                                          DiscreteDistribution *iDis, bool progress );
\end{verbatim}
\end{quote}
Other parameters common to these methods are:
\begin{description}
\item[\code{progress}]: flag specifying if the iteration numbers must be
  issued along the way.
\item[\code{tmax}]: the maximum number of iterations to be performed.
  When this number is reached, a message is issued warning the user
  that the computation may be imprecise. Note that iterative methods
  usually do not provide a guarantee of precision anyway.
\item[\code{precision}]: a precision parameter used for stopping iterations.
  Typically, iterations stop when two consecutive results have a ``distance''
  less than this parameter. Note that this does not imply in general that
  the result produced is within a distance of the exact value.
\item[\code{initDistribType}]: a specification of the initial distribution
  to be used in the iterations. Recognized types are:
  \code{"Zero"} for the Dirac distribution concentrated on the state
  with index 0;
  \code{"Max"} for the Dirac distribution concentrated on the state
  with largest index;
  \code{"Uniform"} for the uniform distribution over the whole state space,
  and \code{"Custom"} in which case the \code{iDis} parameter is used.
\item[\code{iDis}]: the initial distribution to be used in the
  iterations.
\end{description}

\paragraph{Red Light Green Light (RLGL) Iterative methods.}
The entry point to RLGL algorithms\footnote{The algorithms are described in
\url{https://arxiv.org/abs/2008.02710}.} is the method:
\index{stationary distribution!RLGL method}
\begin{quote}
\begin{verbatim}
Distribution* StationaryDistributionRLGL(int tMax, double epsilon,
                                         DiscreteDistribution *iDis, bool progress,
                                         double alpha, string criterion)
\end{verbatim}
% Distribution* StationaryDistributionRLGL(int tMax, double epsilon,
%                                         DiscreteDistribution *iDis, bool progress);
\end{quote}
Specific parameters to the \code{StationaryDistributionRLGL} are:
\begin{description}
\item[\code{alpha}]: is a parameter in $[0,1]$, used for the PageRank variant:
  $\alpha P + (1-\alpha)\pi_0$; it has the default value 1;
 \item[\code{criterion}]:
   indicates how nodes whose cash should be routed are chosen: available options are
   \begin{description}
     \item[\code{"thresh\_1"}]: absolute cash greater than average (the default value),
     \item[\code{"thresh\_2"}]: cash greater than sqare root of second moment,
     \item[\code{"RR"}]: round robin,
     \item[\code{"PI"}]: all cash is routed, equivalent to power iteration.
   \end{description}
\end{description}
% The second form of \code{StationaryDistributionRLGL()} is calling the first one
% with default parameters \code{alpha}=0 and \code{criterion}=\code{"thresh\_1"}.

\subsubsection{Transient distributions}

The transient distribution is the distribution of the state of the
Markov chain after a given time, starting from some initial state.
Methods performing this calculation are:
\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
  Distribution* & TransientDistributionR( int fromState, double t ) & \\
  Distribution* & TransientDistributionDT( int fromState, int t ) & \\
          \hline
  \end{tabular}
\end{center}

The method \code{TransientDistributionR} performs the calculation for
continuous-time chains. It uses the \code{R} environment.
% , see Section~\ref{sec:R-environment}.
This feature is not available in the current version.
The method \code{TransientDistributionDT}
performs the calculation for discrete-time chains. It uses the
power method.

\subsubsection{Hitting times}
\label{sec:hitting-times}
\index{hitting time}

Hitting times are random variables defined from the Markov chain. They
measure the time it takes for the chain to reach a certain set of states,
starting from some initial state. Methods are available for
directly computing their distribution, computing their average, or
obtaining samples of them via Monte Carlo simulation.

\paragraph*{Computing the hitting time distribution.}
There are no top-level methods for this in the current version.
Derived classes implement such a method when it is known from the theory.

%% \begin{center}
%%   \tt
%%   \begin{tabular}{lll}
%%     \hline
%%     vector<Distribution*> & HittingTimeDistribution(bool *hitSetIndicator) & \\
%%     Distribution* & HittingTimeDistribution(int iState, bool *hitSetIndicator) & \\
%% \hline
%%   \end{tabular}
%% \end{center}


\paragraph*{Computing the average hitting time.}
\index{hitting time!average}
The methods computing the average of the hitting time distributions are:
\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
double*       &	AverageHittingTime(bool *hitSetIndicator) & \\
double*       &	AverageHittingTimeDT(bool *hitSetIndicator) & \\
double*       &	AverageHittingTimeDTIterative(bool *hitSetIndicator) & \\
double**      & AverageHittingTimeDT\_Conditional(bool *hitSetIndicator) & \\
double**      & AverageHittingTimeDT\_ConditionalIterative(bool *hitSetIndicator) & \\
\hline
  \end{tabular}
\end{center}

\noindent
The parameter common to these methods is:
\begin{description}
% \item[\code{iState}]: the index of the initial state.
\item[\code{hitSetIndicator}]: an array of boolean marking the states that
  are in the hitting set with \code{true}, the other ones with \code{false}.
\end{description}

The method \code{AverageHittingTime()} is available for both
discrete-time and continuous-time Markov chains. It calls
\code{AverageHittingTimeDT()} for discrete-time chains. For continuous-time chains,
it performs uniformization, then calls \code{AverageHittingTimeDT()} on the
uniforized chain.

The method \code{AverageHittingTimeDT()}
uses the Gauss-Jordan method
to solve the linear system that provides average hitting times.
The method \code{AverageHittingTimeIterative()} solves (approximately)
the same system with the power method. Both return arrays of the size of the
state space, contaning the average hitting time of the hitting set,
from every state in the state space.

Likewise, the method \code{AverageHittingTimeDT\_Conditional()} computes the average
hitting times \textit{conditioned} on the state hit.
\index{hitting time!conditional on the state hit}
It uses uses the Gauss-Jordan method. The iterative version
\code{AverageHittingTimeDT\_} \code{ConditionalIterative()}
uses an approximate fixed point method to solve each of the linear systems
involved. 
Both return a two-dimensional square array of the size of the state space,
where entry $(i,j)$ represents the conditional hitting time of state $j$
starting from state $i$. If $j$ is not in the hitting set, this number is 0.

These methods apply only to discrete-time chains. They should not be
used with large state spaces.

\paragraph*{Simulating hitting times.}
\index{hitting time!simulation}
Methods for obtaining samples of the hitting times are:

\begin{quote}
  \begin{verbatim}
SimulationResult* SimulateHittingTime(DiscreteDistribution *iDis, bool *hitSetIndicator,
                                      unsigned long int nbSamples, double tMax)
SimulationResult* SimulateHittingTime(cardinalType iState, bool *hitSetIndicator,
                                      unsigned long int nbSamples, double tMax )
SimulationResult* SimulateHittingTimeCT(DiscreteDistribution *iDis, bool *hitSetIndicator,
                                        unsigned long int nbSamples, double tMax )
SimulationResult* SimulateHittingTimeDT(DiscreteDistribution *iDis, bool *hitSetIndicator,
                                        unsigned long int nbSamples, double tMax )
\end{verbatim}
\end{quote}

The method \code{SimulateHittingTime()} obtains sample of the distribution
with Monte Carlo simulation. It uses the parameters \code{nbSamples} to
specify how many samples should be collected, and \code{tMax} to limit
the duration of simulations. For discrete-time chains, it is interpreted as
maximal the number of steps to perform, and for continuous-time chains,
the maximal value of time. When this limit is reached, it is returned
as the sample. Two variants of the method accept as parameter:
either some initial distribution \code{iDis}, or some initial state \code{iState}.

Depending on the type of Markov chain, the specific methods
\code{SimulateHittingTimeCT()} or \code{Simulate} \code{HittingTimeDT()}
are called. They accept only an initial distribution parameter \code{iDis}.
If the hitting time from a specific initial state is needed, then convert
this state to a \code{DiracDistribution()} (see Section~\ref{sec:DiracDistribution})
or use the generic \code{SimulateHittingTime()}.

All simulation methods return a \code{SimulationResult} object.
\index{simulation result@\code{SimulationResult}}
See its description in Section~\ref{sec:simulation}.
The samples are recovered as a \code{vector<double>} for continuous-time Markov chains,
and a \code{vector<simLenType>} for discrete-time Makov chains.

\subsubsection{Output}
\label{sec:markov-chain-output}
\index{output formats}

Markov chain objects can be saved to a file using a number of formats.
The methods for doing this are:
\begin{center}\tt
  \begin{tabular}{lll}
    \hline
    void & Write(std::ostream* out, string modelName, inoutFormat format ) & \\
    void & Store(std::string modelName, inoutFormat format ) & \\
  \hline
\end{tabular}
\end{center}
The method \code{Write()} places the output in the stream \code{out}.
The method \code{Store()} places the output into a file. The file name
is obtained by concatenating the \code{modelName} with an extension depending
on the output format specified by parameter \code{format}.
The formats currently supported are described in Section~\ref{sec:basic-types}.

There is also a serialization method
\begin{center}\tt
  \begin{tabular}{lll}
    \hline
  std::string & toString( inoutFormat format ) & \\
  \hline
\end{tabular}
\end{center}
which converts the result of \code{Write()} into a string.
  
\subsection{Implementations}

The following Markov chain models implemented.
When a model can be considered as a sub-case of another model, the corresponding
class inherits of that of the super-model.
A hierarchy of some known models of the literature is proposed in Appendix~\ref{chap:zoo},
in continuous time (Appendix~\ref{sec:zoo-CT}) and discrete time (Appendix~\ref{sec:zoo-DT}).
Since not all the models are implemented yet, the inheritance relation between the classes
described below is restricted to implemented ones.

Currently implemented models:
%% The specific
%% implementation \code{AbstractMarkovChain} is described in Section~\ref{sec:abstract}.
\begin{center}
  \small
\begin{tabular}{lll}
  Name & description & inherits from \\
  \hline
  \code{TwoStateDiscrete} & generic discrete-time chain with two states &
  \code{MarkovChain} \\
  \code{TwoStateContinuous} & generic continuous-time chain with two states &
  \code{MarkovChain} \\
  \code{Homogeneous1DRandomWalk} & discrete-time random walk on subsets of \N &
  \code{MarkovChain} \\
  \code{Homogeneous1DBirthDeath} & continuous-time birth-death on subsets of \N &
  \code{MarkovChain} \\
  \code{HomogeneousMultiDRandomWalk} & discrete-time random walk on subsets of $\N^d$ &
  \code{MarkovChain} \\
  \code{HomogeneousMultiDBirthDeath} & continuous-time random walk on subsets of $\N^d$ &
  \code{MarkovChain} \\
  \code{MMPP} & the Markov-modulated Poisson process on $\N$ &
  \code{MarkovChain} \\
  \code{PoissonProcess} & the usual Poisson process on $\N$ &
  \code{Homogeneous1DBirthDeath} \\
  \code{Felsenstein81} & continuous-time model for genome evolution &
  \code{MarkovChain} \\
  \hline
\end{tabular}
\end{center}


\subsubsection{\code{TwoStateDiscrete}}
\label{sec:twoStateDiscrete}
\index{TwoStateDiscrete@\code{TwoStateDiscrete}!reference}

This class implements the two-state discrete-time Markov chain.
This is a discrete-time Markov chain model, characterized by:
\begin{itemize}
\item the probability of jumps from state 0 to state 0, $a$,
\item the probability of jumps from state 1 to state 1, $b$.
\end{itemize}

It is a currently class derived from \code{MarkovChain}: it probably
should be derived from \code{Homogeneous1DRandomWalk}.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteMarkovChain/marmoteTwoStateDiscrete.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} This class has a single constructor:
\begin{quote}
\begin{verbatim}
   TwoStateContinuous( double a, double b );
\end{verbatim}
\end{quote}

\paragraph{Re-implemented methods.} 
The following methods have been re-implemented within \code{TwoStateDiscrete}:
\begin{quote}
\begin{verbatim}
std::vector<cardinalType> AbsorbingStates();
std::vector< std::vector<cardinalType> > RecurrentClasses();
std::vector< std::vector<cardinalType> > CommunicatingClasses();
stateType Period();
bool IsIrreducible();
bool IsAccessible(stateType stateFrom, stateType stateTo);
SimulationResult* SimulateChain(double tMax, bool stat, bool traj, bool incr, bool trace);
\end{verbatim}
\end{quote}

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
TwoStateDiscrete* Copy();
BernoulliDistribution* StationaryDistribution();
BernoulliDistribution* TransientDistribution( double t );
std::vector<Distribution*> HittingTimeDistribution( bool* hitSetIndicator );
double* AverageHittingTime( bool* hitSetIndicator );
\end{verbatim}
\end{quote}

The parameter of \code{TransientDistribution()} is \code{t}, the time (measured in the number of time steps)
at which the distributions should be evaluated. This methodcomputes the transient
distribution $\pi(t)$ with the exact formulas:
\begin{eqnarray*}
  p_0(t) & = & \frac{1}{a + b - 2}
  \left(b - 1 + ( a + b - 1 )^t ( (a-1) p_0(0) + ( 1 - b) p_1(0) ) \right) 
  \\
  p_1(t) & = & \frac{1}{a + b - 2}
  \left(a - 1 - ( a + b - 1 )^t ( (a-1) p_0(0) + ( 1 - b) p_1(0) ) \right) 
  ~.
\end{eqnarray*}

The method \code{StationaryDistribution()} returns the stationary distribution:
it is a Bernoulli distribution given by:
\begin{displaymath}
  \pi ~ = ~ \left( \frac{b-1}{a+b-2}, \frac{a-1}{a+b-2}
  \right)
\end{displaymath}
and is defined only when $(a,b)\not=(1,1)$.

Hitting time distributions are either Dirac distributions at 0, or
geometric distributions on $\N^*$.
\index{hitting time!distribution!for two-state Markov chains}
The situation where the hitting set
is empty is handled: the (defective) distribution \code{GeometricDistribution(1.0)}
is returned by \code{HittingTimeDistribution()}, and the constant \code{INFINITE\_DURATION} is
returned by \code{Average} \code{HittingTime()} (see Section~\ref{sec:distribution-features}).

\subsubsection{\code{TwoStateContinuous}}
\label{sec:twoStateContinuous}
\index{TwoStateContinuous@\code{TwoStateContinuous}!reference}

This class implements the two-state continuous-time Markov chain.
This is a continuous-time Markov chain model, characterized by:
\begin{itemize}
\item the rate of jumps from state 0 to state 1, $\alpha$,
\item the rate of jumps from state 1 to state 0, $\beta$.
\end{itemize}

It is currently a class derived from \code{MarkovChain}: it probably
should be derived from \code{Homogeneous1DBirthDeath}.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteMarkovChain/marmoteTwoStateContinuous.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} This class has a single constructor:
\begin{quote}
\begin{verbatim}
   TwoStateContinuous( double alpha, double beta );
\end{verbatim}
\end{quote}

\paragraph{Re-implemented methods.} 
The following methods have been re-implemented within \code{TwoStateContinuous}:
\begin{quote}
\begin{verbatim}
std::vector<cardinalType> AbsorbingStates();
std::vector< std::vector<cardinalType> > RecurrentClasses();
std::vector< std::vector<cardinalType> > CommunicatingClasses();
stateType Period();
bool IsIrreducible();
bool IsAccessible(stateType stateFrom, stateType stateTo);
SimulationResult* SimulateChain(double tMax, bool stat, bool traj, bool incr, bool trace);
\end{verbatim}
\end{quote}

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
TwoStateDiscrete* Copy();
TwoStateDiscrete* Uniformize();
TwoStateDiscrete* Embed();
BernoulliDistribution* StationaryDistribution();
BernoulliDistribution* TransientDistribution( double t );
std::vector<Distribution*> HittingTimeDistribution( bool* hitSetIndicator );
double* AverageHittingTime( bool* hitSetIndicator );
\end{verbatim}
\end{quote}

The methods \code{Uniformize()} and \code{Embed()} return a discrete two-state
Markov chain.
\index{uniformization!for two-state Markov chains}
\index{embedding!for two-state Markov chains}

The parameter of \code{TransientDistribution()} is \code{t}, the time at which the
distributions should be evaluated. This method computes the transient
distribution $\pi(t)$ with the exact formulas:
\begin{eqnarray*}
  p_0(t) & = & \frac{1}{\alpha+\beta}
  \left(\beta+e^{-(\alpha+\beta)t}(\alpha p_0(0)-\beta p_1(0)) \right) 
  \\
  p_1(t) & = & \frac{1}{\alpha+\beta}
  \left(\alpha-e^{-(\alpha+\beta)t}(\alpha p_0(0)-\beta p_1(0))
  \right)
  ~.
\end{eqnarray*}

The method \code{StationaryDistribution()} returns the stationary distribution:
it is a Bernoulli distribution given by:
\begin{displaymath}
  \pi ~ = ~ \left( \frac{\beta}{\alpha+\beta}, \frac{\alpha}{\alpha+\beta}
  \right)
\end{displaymath}
and is defined only when $(\alpha,\beta)\not=(0,0)$.

Hitting time distributions are either Dirac distributions at 0, or
exponential distributions.
\index{hitting time!distribution!for two-state Markov chains}
The situation where the hitting set
is empty is handled: the (defective) distribution \code{ExponentialDistribution(INFINITE}
\code{\_DURATION)}
is returned by \code{HittingTimeDistribution()}, and the constant \code{INFINITE\_DURATION} is
returned by \code{Average} \code{HittingTime()} (see Section~\ref{sec:distribution-features}).


\subsubsection{\code{Homogeneous1DBirthDeath}}
\label{sec:homogeneous1DBirthDeath}
\index{Homogeneous1DBirthDeath@\code{Homogeneous1DBirthDeath}!reference}

This class implements the 1-dimensional birth and death process with
homogeneous transition rates. This is a continuous-time Markov chain
model, characterized by:
\begin{itemize}
\item the number of states (or ``size'') $N$, possibly \code{INFINITE\_STATE\_SPACE\_SIZE}
  \index{infinite state space@\texttt{INFINITE\_STATE\_SPACE\_SIZE}!in birth-death processes}
  \index{infinity (numerical representation)!\code{INFINITE\_STATE\_SPACE\_SIZE}}
\item the rate of jumps to the right, $\lambda$,
\item the rate of jumps to the left, $\mu$.
\end{itemize}

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteMarkovChain/marmoteHomogeneous1dBirthDeath.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} Two constructors are available.
\begin{quote}
\begin{verbatim}
Homogeneous1DBirthDeath( double lambda, double mu );
Homogeneous1DBirthDeath( int n, double lambda, double mu );
\end{verbatim}
\end{quote}
The first form defines a birth-death process with \N\ as state space.
The second one defines a birth-death process with $[0..n-1]$ as state space.

\paragraph{Re-implemented methods.} 

The following methods have been re-implemented within \code{Homogeneous1DBirthDeath}:
\begin{quote}
\begin{verbatim}
SimulationResult* SimulateChain(double tMax, bool stat, bool traj, bool incr, bool trace);
\end{verbatim}
\end{quote}
% The method \code{SimulateChain} performs Monte Carlo simulation of the chain.
Simulation is possible for infinite-state birth-death processes. However, overflow of the
state is not handled currently.

\paragraph{Specific methods.}


The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
Homogeneous1DBirthDeath* Copy();
Homogeneous1DBirthDeath* Uniformize();
MarkovChain* Embed();
DiscreteDistribution* TransientDistribution(double t,int nMax);
DiscreteDistribution* ApproxTransientDistribution(double t,int nMax);
GeometricDistribution* StationaryDistribution();
DiscreteDistribution* StationaryDistribution(int nMax);
void MakeMarkovChain();
\end{verbatim}
\end{quote}

The \code{Uniformization()} method returns a homogeneous discrete-time random walk.
However, the \code{Embedding()} method does not: it returns a generic Markov chain.
\index{uniformization!for homogeneous birth-death processes}
\index{embedding!for homogeneous birth-death processes}

The parameters of these methods are: \code{t}, the time at which distributions should be
evaluated, and \code{nMax}, the index of the largest state. Note that the ``size''
parameter specified at the creation of the object is ignored by these methods.

The method \code{TransientDistribution()} computes the transient distribution $\pi(t)$
with exact formulas (currently incomplete).

The method \code{ApproxTransientDistribution()}
computes an approximation to the transient distribution for a 
\code{Homogeneous1DBirthDeath} chain, computed as an interpolation between the
initial distribution $\pi(0)$ and the stationary distribution $\pi$:
\begin{displaymath}
  \pi(t) ~ = ~ ( 1 - e^{-(\lambda+\mu)t} ) \pi + e^{-(\lambda+\mu)t} \pi_0.
\end{displaymath}

The method \code{StationaryDistribution()} returns the stationary distribution for
the birth-death process on \N. It is a geometric distribution. When $\lambda \geq \mu$,
the geometric distribution with parameter 1 is returned, to represent the defective
distribution with a ``Dirac mass at $+\infty$''.

The method \code{StationaryDistribution(int n)} returns the stationary distribution for
the birth-death process on $[0..n]$ (and not $[0..n-1]$). It is a truncated geometric
distribution:
\begin{displaymath}
  \pi_k ~ = ~ \frac{(1 - \lambda/\mu)(\lambda/\mu)^k}{1 - (\lambda/\mu)^{n+1}},
  \quad\text{if $\lambda\not=\mu$},
  \qquad
  \pi_k ~ = ~ \frac{1}{n+1}
  \quad\text{if $\lambda=\mu$,}
  \quad k=0..n.
\end{displaymath}
When $\lambda=\mu$, this is a discrete uniform distribution, but the class
\code{UniformDiscreteDistribution} is not used.

The method \code{MakeMarkovChain()} creates a generator for the Markov chain
object, of the type \code{SparseMatrix}. This does not apply to chains on \N.

\subsubsection{\code{Homogeneous1DRandomWalk}}
\label{sec:homogeneous1DRandomWalk}
\index{Homogeneous1DRandomWalk@\code{Homogeneous1DRandomWalk}!reference}

This class implements the 1-dimensional random walk with homogeneous
transition probabilities. This is a discrete-time Markov chain
model, characterized by:
\begin{itemize}
\item the number of states (or ``size'') $N$, possibly \code{INFINITE\_STATE\_SPACE\_SIZE}
  \index{infinite state space@\texttt{INFINITE\_STATE\_SPACE\_SIZE}!in random walks}
\item the probability to jump to the right, $p$
\item the probability to jump to the left, $q$.
\end{itemize}
The model is valid if $p + q \leq 1$.
The probability to stay at the same position is $1 - p - q$.
 
\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteMarkovChain/marmoteHomogeneous1dRandomWalk.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} Two constructors are available.
\begin{quote}
\begin{verbatim}
Homogeneous1DRandomWalk( double p, double q );
Homogeneous1DRandomWalk( int n, double p, double q );
\end{verbatim}
\end{quote}
The first form defines a random walk process with \N\ as state space.
The second one defines a random walk process with $[0..n-1]$ as state space.

\paragraph{Re-implemented methods.} 

The following methods have been re-implemented within \code{Homogeneous1DBirthDeath}:
\begin{quote}
\begin{verbatim}
SimulationResult* SimulateChain(double tMax, bool stat, bool traj, bool incr, bool trace);
void Write( std::ostream* out, string modelName, inoutFormat format );
void Store( string modelName, inoutFormat format );
\end{verbatim}
\end{quote}

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
Homogeneous1DRandomWalk* Copy();
SimulationResult* SimulateChain(long int tMax, bool stat, bool traj, bool trace);
DiscreteDistribution* ApproxTransientDistribution(int t, int nMax);
Distribution* StationaryDistribution();
void MakeMarkovChain();
void Write(string format, string prefix);
\end{verbatim}
\end{quote}
The method \code{SimulateChain} performs Monte Carlo simulation of the chain.
Simulation is possible for infinite-state birth-death processes. However, overflow of the
state is not handled currently.\footnote{Observe that the method does \textit{not}
  override \code{MarkovChain::SimulateChain} because its signature is actually that
  of \code{MarkovChain::SimulateChainDT}. This mismatch will be corrected in a lated version.}

The parameters of the methods devoted to transient and stationary
distributions are: \code{t}, the time at which distributions should be
evaluated, and \code{nMax}, the index of the largest state.

The method \code{ApproxTransientDistribution()}
computes an approximation to the transient distribution for a 
\code{Homogeneous1DRandomWalk} chain, computed as an interpolation between the
initial distribution $\pi(0)$ and the stationary distribution $\pi$:
\begin{displaymath}
  \pi(t) ~ = ~ ( 1 - \omega^t ) \pi + \omega^t \pi_0,
  \quad
  \text{with $\omega = 1 - p - q + 2 \sqrt{pq} \cos(\pi/n)$.}
\end{displaymath}
Note that method uses its own parameter \code{n} and ignores 
the ``size'' parameter specified at the creation of the object.

The method \code{StationaryDistribution()} returns the stationary distribution for
the birth-death process. When the process is on \N, this stationary distribution
is a geometric distribution. When $p \geq q$,
the geometric distribution with parameter 1 is returned, to represent the defective
distribution with a ``Dirac mass at $+\infty$''.

The method \code{MakeMarkovChain()} creates a generator for the Markov chain
object, of the type \code{SparseMatrix}. This does not apply to chains on \N.

Methods \code{Write()} and \code{Store()} (see Section~\ref{sec:markov-chain-output})
produce a representation of the model. Supported
formats for objects \code{Homogeneous1DRandomWalk} are:
\begin{itemize}
\item \code{FORMAT\_MARMOTE}: the standard sparse \code{Marmote}
  format;
\item \xborne\ format \code{FORMAT\_XBORNE\_SIZE} for state space representations,
  \code{FORMAT\_XBORNE\_RII} and \code{FORMAT\_XBORNE\_CUU} for row-based and
  column-based outputs; \index{Xborne!output to}
\item matrix formats \code{FORMAT\_MARCA} and \code{FORMAT\_MATRIXMARKET\_SPARSE};
\item Psi3 \code{yaml} configuration file \code{FORMAT\_PSI3};
\item \code{R} full-matrix format \code{FORMAT\_R}.
\end{itemize}

\subsubsection{\code{HomogeneousMultiDRandomWalk}}
\label{sec:homogeneousMultiDRandomWalk}
\index{HomogeneousMultiDRandomWalk@\code{HomogeneousMultiDRandomWalk}!reference}

This class implements the multidimensional random walk with homogeneous
transition probabilities. This is a discrete-time Markov chain
model, characterized by:
\begin{itemize}
\item the number of dimensions $d$,
\item the number of states in each dimension, possibly \code{INFINITE\_STATE\_SPACE\_SIZE}
  \index{infinite state space@\texttt{INFINITE\_STATE\_SPACE\_SIZE}!in random walks}
\item the probabilities to jump to the right in each dimension, ($p_1$, \ldots, $p_d$),
\item the probability to jump to the left in each dimension, ($q_1$, \ldots, $q_d$).
\end{itemize}
The model is valid if $\sum_{k=1}^d (p_i + q_i) \leq 1$.
The probability to stay at the same position is $r = 1 - \sum_{k=1}^d (p_i + q_i)$.

Objects of this class are equipped with a generator object, from the
\code{HomogeneousMultidTransition} class (see Section~\ref{sec:multidtransition}).

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteMarkovChain/marmoteHomogeneousMultidRandomWalk.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} Two constructors are available.
\begin{quote}
\begin{verbatim}
  HomogeneousMultiDRandomWalk( unsigned int nbDims, double* p, double* q );
  HomogeneousMultiDRandomWalk( unsigned int nbDims, stateType* sz, double* p, double* q );
\end{verbatim}
\end{quote}
In both, \code{nbDims} is the number of dimensions $d$ and \code{p}, \code{q}
are arrays of size $d$ containing the probabilities $p_i$ and $q_i$.
The first form defines a random walk with $\N^d$ as state space.
The second one defines a random walk with $\times_{i=1}^d [0..n_i-1]$ as state space,
where the $n_i$ are the values in the array \code{sz}.

\paragraph{Re-implemented methods.}
The following methods are reimplemented.
\index{stationary distribution!for multidimensional random walks}
\index{hitting time!for multidimensional random walks}
\begin{quote}
\begin{verbatim}
DiscreteDistribution* StationaryDistribution();
int* SimulateHittingTime(cardinalType iState, bool *hitSetIndicator,
                         unsigned long int nbSamples, simLenType tMax);
Store(string modelName, inoutFormat format);
\end{verbatim}
\end{quote}
The \code{SimulateHittingTime} method works only for finite chains,
although this condition is not currently enforced.

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
void MakeMarkovChain();
DiscreteDistribution* StationaryDistribution();
\end{verbatim}
\end{quote}

The method \code{MakeMarkovChain()} creates a generator for the Markov chain
object, of the type \code{SparseMatrix}. It applies only to finite chains of dimension
1 or 2.

The method \code{StationaryDistribution()} returns the stationary distribution for
the birth-death process. It applies only to chains on finite state spaces.
The distribution is a product of truncated geometric distributions, see
\code{Homogeneous1DRandomWalk}.

The method \code{Store()} (see Section~\ref{sec:markov-chain-output})
handles specifically the format \code{FORMAT\_XBORNE\_RII}.
Other formats are directly handled by the main class \code{MarkovChain}.

\subsubsection{\code{HomogeneousMultiDBirthDeath}}
\label{sec:homogeneousMultiDBirthDeath}
\index{HomogeneousMultiDBirthDeath@\code{HomogeneousMultiDBirthDeath}!reference}

This class implements the multidimensional birth-death process with homogeneous
transition rates. This is a continuous-time Markov chain
model, characterized by:
\begin{itemize}
\item the number of dimensions $d$,
\item the number of states in each dimension, possibly \code{INFINITE\_STATE\_SPACE\_SIZE}
  \index{infinite state space@\texttt{INFINITE\_STATE\_SPACE\_SIZE}!in random walks}
\item the rates of jumps to the right in each dimension, ($\lambda_1$, \ldots, $\lambda_d$),
\item the rates of jumps to the left in each dimension, ($\mu_1$, \ldots, $\mu_d$).
\end{itemize}

Objects of this class are equipped with a generator object, from the
\code{HomogeneousMultidTransition} class (see Section~\ref{sec:multidtransition}).

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteMarkovChain/marmoteHomogeneousMultidBirthDeath.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} Two constructors are available.
\begin{quote}
\begin{verbatim}
HomogeneousMultiDBirthDeath(unsigned int nbDims, double* lambda, double* mu);
HomogeneousMultiDBirthDeath(unsigned int nbDims, stateType* sz, double* lambda, double* mu);
\end{verbatim}
\end{quote}
In both, \code{nbDims} is the number of dimensions $d$ and \code{lambda}, \code{mu}
are arrays of size $d$ containing the rates $\lambda_i$ and $\mu_i$.
The first form defines a birth-death process with $\N^d$ as state space.
The second one defines a birth-death process with $\times_{i=1}^d [0..n_i-1]$ as state space,
where the $n_i$ are the values in the array \code{sz}.

\paragraph{Re-implemented methods.}
The following methods are reimplemented.
\index{stationary distribution!for multidimensional random walks}
\index{hitting time!for multidimensional random walks}
\begin{quote}
\begin{verbatim}
DiscreteDistribution* StationaryDistribution();
int* SimulateHittingTime(cardinalType iState, bool *hitSetIndicator,
                         unsigned long int nbSamples, simLenType tMax);
Store(string modelName, inoutFormat format);
\end{verbatim}
\end{quote}
The \code{SimulateHittingTime} method works only for finite chains,
although this condition is not currently enforced.

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
void MakeMarkovChain();
DiscreteDistribution* StationaryDistribution();
\end{verbatim}
\end{quote}

The method \code{MakeMarkovChain()} creates a generator for the Markov chain
object, of the type \code{SparseMatrix}. It applies only to finite chains of dimension
1 or 2.

The method \code{StationaryDistribution()} returns the stationary distribution for
the birth-death process. It applies only to chains on finite state spaces.
The distribution is a product of truncated geometric distributions, see
\code{Homogeneous1DRandomWalk}.

The method \code{Store()} (see Section~\ref{sec:markov-chain-output})
handles specifically the format \code{FORMAT\_XBORNE\_RII}.
Other formats are directly handled by the main class \code{MarkovChain}.

\subsubsection{\code{MMPP}}
\label{sec:MMPP}
\index{MMPP@\code{MMPP}!reference}
\index{Markov-modulated Poisson process}
\index{Poisson process!Markov modulated}

This class implements the generic Markov-modulated Poisson process.
This is a continuous-time Markov chain model, characterized by:
\begin{itemize}
\item a continuous-time Markov chain, called the ``environment'', with generator $Q$;
\item a vector of arrival rates $r$.
\end{itemize}
It is a ``pure birth'' process which behaves as follows.
When the environment is in state $i$, arrivals occur according to a Poisson
process of rate $r_i$. State transitions of the environment occur independently
of the arrival processes.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteMarkovChain/marmotePoissonProcess.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} This class has a single constructor:
\begin{quote}
\begin{verbatim}
MMPP( TransitionStructure* env, double* rates );
\end{verbatim}
\end{quote}
The parameter \code{env} is the generator of the environment, the parameter
\code{rates} contains the rates $r_i$.

\paragraph{Re-implemented methods.} None.

\paragraph{Specific methods.}
The following methods are specific to \code{MMPP}:
\begin{quote}
\begin{verbatim}
SimulationResult* SimulateChain(double tMax,
                          DiscreteDistribution* numberDis, DiscreteDistribution* phaseDis,
                          bool traj, bool trace=false, bool withIncrements=false );
MMPP* Copy();
\end{verbatim}
\end{quote}
The parameters and behavior of \code{SimulateChain()}
are similar to \code{MarkovChain::SimulateChain()}
(see Section~\ref{sec:simulation}) but it admits
\textit{two} parameters for specifying the initial conditions.
Parameter \code{numberDis} is for the initial value of the state of the
arrival process: a random number in $\N$. Parameter \code{phaseDis} is
the distribution of the state (also known as ``phase'') of the environment at
time $t=0$. 

\noindent
Note: the output of the simulation (when \code{trace} is enabled) handes the `state` information
in a specific way. What is displayed is $2 a + s$, where $a$ is the number of arrivals so far,
and $s$ the index of the current state of the enviroment. Since events are either arrivals
or state transitions, computing the diffence between to consecutive pseudo-states can unambiguously 
recover the number of arrivals and the states \textit{except} if a state transition increments 
the index by 2. This experimental and imperfect feature will be deprecated in future releases.

\subsubsection{\code{PoissonProcess}}
\label{sec:poissonProcess}
\index{PoissonProcess@\code{PoissonProcess}!reference}

This class implements the Poisson counting process.  This is a
continuous-time Markov chain model, characterized by a unique
parameter $\lambda$: its rate or intensity.  It is a ``pure birth''
process, and is derived from \code{Homogeneous1DBirthDeath}:
the parameter $\mu$ of this model is set to 0. 

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteMarkovChain/marmotePoissonProcess.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} This class has a single constructor:
\begin{quote}
\begin{verbatim}
	PoissonProcess( double lambda );
\end{verbatim}
\end{quote}

\paragraph{Re-implemented methods.} 
The following methods have been re-implemented within \code{PoissonProcess}:
\begin{quote}
\begin{verbatim}
	Distribution* TransientDistribution(double t);
	GeometricDistribution* StationaryDistribution();
	SimulationResult* SimulateChain(double tMax, bool stat, bool traj, bool incr, bool trace);
\end{verbatim}
\end{quote}

The method \code{TransientDistribution()} returns a Poisson distribution.
There is no stationary distributions for Poisson processes: the method
\code{StationaryDistribution()} returns a \code{GeometricDistribution(1.0)}
object, that is, a Dirac mass at infinity. See Section~\ref{sec:GeometricDistribution}.

\paragraph{Specific methods.} None.

\subsubsection{\code{Felsenstein81}}
\label{sec:Felsenstein81}
\index{Felsenstein81@\code{Felsenstein81}!reference}

The Felsenstein 81 model is a continuous-time Markov chain with a state space
of size 4 an generator defined by:
\begin{displaymath}
  q_{i,j} ~=~ \mu p_i ~, \quad i\not=j
  \qquad 
  q_{i,i} ~=~ \mu ( 1 - p_i ) ~,
\end{displaymath}
where $\pi=(p_1,p_2,p_3,p_4)$ is a probability distribution, and $\mu>0$.
The distribution $\pi$ turns out to be the stationary distribution.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteMarkovChain/biology/felsenstein81.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} Two constructors are available:

\begin{quote}
\begin{verbatim}
  Felsenstein81( double p[4] , double mu);
  Felsenstein81( DiscreteDistribution* d, double mu);
\end{verbatim}
\end{quote}
In both versions, the parameter $\mu$ is passed as variable \code{mu}.
The distribution $\pi$ is passed as an array of four elements in the first version,
and as a \code{DiscreteDistribution} object in the second. It must have 4 values,
although this condition is not currently enforced.

\paragraph{Re-implemented methods.}

The following method has been re-implemented within \code{Felsenstein81}:

\begin{quote}
\begin{verbatim}
      Distribution* HittingTimeDistribution(int iState, bool* hittingSet);
      double* AverageHittingTime(bool* hittingSet);
      SimulationResult* SimulateChain(double tMax,
                                      bool stats, bool traj, bool incr, bool trace );
\end{verbatim}
\end{quote}

The method \code{HittingTimeDistribution()} uses the exact formula:
\begin{displaymath}
  P( \tau_{\mathcal H} \leq t ) ~ = ~ 1 - e^{-\mu t \pi({\mathcal H})},
\end{displaymath}
where $\pi({\mathcal H})$ is the mass of the hitting set ${\mathcal H}$ with the
measure $\pi$, and returns an \code{ExponentialDistribution} object.
The method \code{AverageHittingTime} uses the same formula.
\index{hitting time!distribution!for Felsenstein 81 models}

\paragraph{Specific methods.} The following methods are specific to the class.

\begin{quote}
\begin{verbatim}
      void MakeMarkovChain();
      DiscreteDistribution* TransientDistribution(int fromState, double t);
      DiscreteDistribution* TransientDistribution(double t);
      DiscreteDistribution* StationaryDistribution();
\end{verbatim}
\end{quote}

The method \code{MakeMarkovChain()} creates a generator for the Markov chain
object, of the type \code{SparseMatrix} (although this matrix is full in general).

The methods \code{TransientDistribution()} compute the transient distribution $\pi(t)$
with exact formulas. The first form assumes that the chain starts in the state
specified as argument \code{fromState}. The second one assumes that the chain starts
with its initial distribution as specified by attribute \code{init\_distribution\_}.

The method \code{StationaryDistribution()} returns the exact stationary distribution $\pi$.

\begin{comment}
  % Abstract Markov chains do not exist anymore in Marmote
  % Resurection pending...
\subsection{Abstract Markov chains}
\label{sec:abstract}
\index{Markov chain!abstract}
\index{AbstractMarkovChain@\code{AbstractMarkovChain}!reference}

The parameter \code{IsAbstract} refers to the possibility that a \code{MarkovChain}
object be kept ``abstract'' (or virtual) in the sense that its contents is
left in files but not read in memory.

In addition to the attributes already listed in Section~\ref{sec:MarkovChain},
including the \code{format\_} and \code{model\_name\_} specifiers,
these objects have specific attributes related to abstractness:
\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
  int & abstract\_nbr\_ & \rm the number of parameters describing the chain \\
  string* & abstract\_param\_ & \rm an array of names describing the chain \\
  \hline
  \end{tabular}
\end{center}
The size of array \code{abstract\_param\_} is \code{abstract\_nbr\_}.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteMarkovChain/abstract_markov_chain.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} Two constructors are available:

\begin{quote}
\begin{verbatim}
   AbstractMarkovChain (int sz, timeType t)
   AbstractMarkovChain (string format, string param[], int nbParam, string model_name)
\end{verbatim}
\end{quote}
The first form creates an \code{AbstractMarkovChain} object with
minimal information.  The second one creates an object corresponding
to a model with name \code{model\_name} written in format/language
\code{format}, the files describing it being listed in array
\code{param} (with size given by \code{nbParam}.  The following
formats are compatible with abstract chains: PSI1/MARCA, ERS, XBORNE,
XBORNEPres. They are described in Appendix~\ref{chap:formats}.
However, only abstract chains of the XBORNE type have currently
a functional interface.
\index{Xborne!abstract chain}
\index{MARCA!input format}
\index{PSI!abstract chain}

\paragraph{Re-implemented methods.} The following methods of \code{MarkovChain}
are re-implemented:
\begin{quote}
\begin{verbatim}
  Write (string format, string model_name)
  Distribution * 	StationaryDistributionGthLD ()
  Distribution * 	StationaryDistributionSOR ()
\end{verbatim}
\end{quote}
Method \code{Write()} is currently re-implemented to issue an error message.
Read/Write operations must be performed with a concrete chain. This situation
may change if external packages provide applications to convert their models
in other formats.

The two other methods refer to solution methods provided by
XBORNE. Their re-implementation consists in using the applications of
XBORNE instead of the embedded code.

\paragraph{Specific methods.} The following methods are specific to the class.

\begin{quote}
\begin{verbatim}
	set_abstract_nbr(int abstract_nbr) 
	set_abstract(string abstract[])
	abstract_nbr()
	toString()
	NCDProperty(double epsilon)
	BandIMSUB(std::string model_name)
	Vincent()
	RowVincent()
	Absorbing()
	ProdFundSW(std::string model_name)
	RowSum(std::string model_name)
\end{verbatim}
\end{quote}

Methods \code{set\_abstract\_nbr()} and \code{set\_abstract()} are mutators
for the corresponding attributes. \code{abstract\_nbr()} is the accessor
for \code{abstract\_nbr\_}. There is no accessor for \code{abstract\_param\_}
but \code{toString()} is a utility to provide a description of the object.
 
The methods \code{NCDProperty}, \code{BandIMSUB}, \code{Vincent()},
\code{RowVincent()}, \code{Absorbing()}, \code{ProdFundSW()} and
\code{RowSum()} are entry points to the applications of
XBORNE with the same names.  See the documentation of XBORNE for details.
\end{comment}

\section{The \code{TransitionStructure} object}
\label{sec:transitionStructure}
\index{TransitionStructure@\code{TransitionStructure}!reference}

Transition structures are abstractions for matrices, or weighted graphs.
Transition structures commonly encountered in Markov modeling are
\textit{probability transition matrices}, for discrete-time Markov chains,
and \textit{infinitesimal generators} (or \textit{rate matrices}) for
continuous-time Markov chains. Matrices or transition functions can
occur in various contexts. \marmotecore\ provides a unified presentation
with the \code{TransitionStructure} object and several implementations.

A transition structure maps an ``origin'' space to a ``destination'' space
and associates a value to these ``transitions''.
In the description below, this will be represented by an ``operator'' $T$,
mapping some set $\mathcal{O}$ to some set $\mathcal{D}$. The values will
be denoted as $T_{i,j}$ for $i\in\mathcal{O}$ and $j\in\mathcal{D}$.
The origins $i$ are associated with \textit{rows} and the destinations $j$
with \textit{columns}.

By convention, when the value associated to some possible transition is $T_{i,j} = 0$,
then the transition does not actually exist. Accordingly, it is possible to
speak of the number of transitions from some particular origin $i$, since it
does not necessarily coincide with the cardinal of the set $\mathcal{D}$.
In the vocabulary of (directed) graphs, this is known as the \textit{outdegree}
of node $i$.

\subsection{Common features}

The methods common to \code{TransitionStructure} and derived classes are summarized
in the following tables, grouped by functionalities.

\subsubsection{Definition}

This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteTransitionStructure.h"
\end{verbatim}
\end{quote}

\subsubsection{Attributes and accessors}

All \code{TransitionStructure} objects have the following attributes:
% \footnote{Remember that attributes can be accessed only through member functions.}
\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
  timeType & type\_ & \rm the time type of the structure: discrete or continuous \\
  long int & orig\_size\_ & \rm size of the origin state space \\
  long int & dest\_size\_ & \rm size of the destination state space \\
  \hline
  \end{tabular}
\end{center}

The \code{type\_} attribute has an influence on the type of entries.
It has two possible values: \code{DISCRETE} and \code{CONTINUOUS}.
When it is \code{DISCRETE}, entries must be probabilities, that is,
comprised between 0 and 1. When it is \code{CONTINUOUS}, entries are
arbitrary real numbers.

The ``size'' attributes are, \textit{a priori}, nonnegative integer numbers.
It is however possible to define transition structures over sets which are not finite
but denumerable. In that case, the value of the size attribute is
\code{INFINITE\_STATE\_SPACE\_SIZE}.
\index{infinite state space@\texttt{INFINITE\_STATE\_SPACE\_SIZE}}

These attributes are accessed with the following methods:
\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
    \multicolumn{3}{l}{// accessing the attributes} \\
  timeType & getType() & \rm returns \code{CONTINUOUS} or \code{DISCRETE} \\
  int & origSize() & \rm returns \code{orig\_size\_} \\
  int & destSize() & \rm returns \code{dest\_size\_} \\
  \hline
  \end{tabular}
\end{center}

\smallskip

Other Methods common to all \code{TransitionStructure} objects are:
\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
  \multicolumn{3}{l}{// accessing the entries} \\
  bool   & setEntry(int,int) & \rm set the value of entry $T_{i,j}$ \\
  bool   & addToEntry(int,int,double) & \rm add a value to entry $T_{i,j}$ \\
  double   & getEntry(int,int) & \rm obtain the entry $T_{i,j}$ \\
  int      & getNbElts(int) & \rm obtain the number of non-zero entries \\
  & & \rm (outdegree) for some origin $i$ \\
  int      & getCol(int,int) & \rm obtain the destination of the $k$ transition \\
  & & \rm from some origin $i$  \\
  double   & getEntryByCol(int,int) & \rm obtain the $k$-th non-zero entry \\
  & & \rm in some row $i$  \\
  DiscreteDistribution* & TransDistrib(int) &
  \rm see Section~\ref{sec:trans_distrib} \\
  bool   & ReadEntry(ostream*); \\
  double & RowSum(int) & \rm evaluation of the sum $\sum_j T_{i,j}$ for some $i$ \\
  \multicolumn{3}{l}{// transformations} \\
  TransitionStructure* & Uniformize() & \rm see Section~\ref{sec:unif} \\
  TransitionStructure* & Embed() & \rm see Section~\ref{sec:unif} \\
  TransitionStructure* & Transpose() & \rm transposition of the matrix \\
  \multicolumn{3}{l}{// actions of a transition} \\
  void & EvaluateMeasureInPlace(double*,double*) &
  \rm evaluate the action on a mesure: $\pi T$ \\
  DiscreteDistribution* & EvaluateMeasure(DiscreteDistribution*) &
  \rm evaluate the action on a mesure: $\pi T$ \\
  & & \rm version with \code{Distribution} objects \\
  void & EvaluateMeasurePageRank(double*,double* &
  \rm evaluate the action on a mesure: $\pi T_\alpha$ \\
  & \qquad\qquad\qquad\qquad\qquad\qquad double) &
  \rm see Section~\ref{sec:action} \\
  void & EvaluateValue(double*,double*) & \rm evaluate the action on a value: $Tv$ \\
  double & EvaluateValueState(double*,cardinalType) & \rm evaluate the action on a value \\
  & & \rm at a specific state: $(Tv)_i$ \\
  void & Write(std::ostream*, std::string, &
  \rm writes the matrix using some format \\
  &  \qquad\qquad\qquad\qquad\qquad\qquad  inoutFormat) & \\
  \hline
  \end{tabular}
\end{center}

Note that 
the \code{addToEntry()} method modifies an entry by adding some value \code{val}
to it, or creates an entry if none was found.
The methods \code{setEntry()} and \code{addToEntry()} return a boolean,
\code{true} if the operation was successful, \code{false} otherwise,
typically when parameters \code{i,j} are out of range.

The \code{Transpose()} method computes the transposed transition structure,
in which origin and destination states are exchanged, and the directions of
transitions are reverted while keeping their weight or label.
The result is stored internally.
%% The \code{getReverted()} method returns
%% this transposed matrix; it computes it before if not already present.

\subsubsection{Probabilistic Transitions}
\label{sec:trans_distrib}

In the context of Markov chains, transitions are of random nature.
The entries in a row of a transition structure encode the random law of transitions
from the corresponding origin state $i$ to the destination space $\mathcal{D}$.
The \code{TransDistrib()} method extracts this law as a discrete distribution
on $\mathcal{D}$.

Unless the convention is explicitly different in the implementation of a derived
class, the distribution is obtained as follows:
\begin{itemize}
\item
When the time type is discrete, the values $T_{i,j}$ are directly intepreted as
transition probabilities.

\item
When the time type is continuous, the probabilities returned are values $T_{i,j}$ are 
\begin{displaymath}
  p_{i,j} ~ = ~ \frac{T_{i,j}}{\sum_{k\in\mathcal{D}} T_{i,k}}.
\end{displaymath}
\end{itemize}

\subsubsection{Actions as an operator}
\label{sec:action}

Transition structures can ``operate'' on measures and values.
In linear algebra terminology, these operations correspond to left- and right-
vector/matrix multiplications.

Measures are defined on the destination space. The action of operator $T$
on measure $\pi$, denoted as $\pi T$, results in another measure with
weights:
\begin{displaymath}
  (\pi T)_j ~ = ~ \sum_{i\in\mathcal{D}} \pi_i T_{i,j},
  \qquad
  \text{for all $j\in\mathcal{D}$.}
\end{displaymath}

Values are defined on the origin space. The action of operator $T$
on value $v$, denoted as $Tv$, results in another value:
\begin{displaymath}
  (Tv)_i ~ = ~ \sum_{j\in\mathcal{D}} T_{i,j} v_j,
  \qquad
  \text{for all $j\in\mathcal{D}$.}
\end{displaymath}

These operations are realized by methods
\code{EvaluateMeasureInPlace()} (which stores its result in a table of
values passed as argument), \code{EvaluateMeasure()} (which returns
its result as a \code{Distribution} object), and
\code{evaluateValue()}.

The form \code{EvaluateMeasurePageRank()} is similar to
\code{EvaluateMeasureInPlace()} but uses as operator:
\begin{displaymath}
  T_\alpha = \alpha T + \frac{1-\alpha}{N} \mathbf{1} \mathbf{1}'
\end{displaymath}
where $\alpha$ is a real number (presumably in the interval $[0,1]$),
$\mathbf{1}$ is the vector with all entries equal to 1, and $N$ is
the cardinal of the state space.

\subsubsection{Uniformization and Embedding}
\label{sec:unif}
\index{uniformization}\index{Markov chain!uniformization}
\index{embedding}\index{Markov chain!embedding}

The \code{uniformize()} and \code{embed()} methods transform a
continuous-time structure into a discrete-time one. As such, they do
not operate on discrete-time transition structures: they just return a
copy of the original object in that case.

\textit{Uniformization} consists in considering the evolution of a
continuous-time Markov chain at the pace of a Poisson process with a
constant rate $\nu$, called the uniformization factor. All events of
the Markov chain occurs at instants of this Poisson process. However, some
events may be self-transitions that do not change the state. The result
is a discrete-time structure. Algebraically,
\begin{displaymath}
  T^{\nu} ~ = ~ I + \frac{1}{\nu} T.
\end{displaymath}
The operation is possible for a range of values of $\nu$. By default,
the value chosen is the minimum possible: $\nu = \max_i |T_{ii}|$.

\textit{Embedding} consists in returning the discrete-time chain with
transition probabilities obtained with the \code{TransDistrib()}
method (see Section~\ref{sec:trans_distrib}). 

\subsubsection{I/O}

The \code{Write()} method outputs the structure on some file
decriptor, using a given format (see
Appendix~\ref{chap:formats}). Supported formats are:
XBORNE (Rii variant: by increasing row and increasing columns), MARCA, Matrix-Market sparse
and full, Ers, Python (numpy), Maple, R, SCILAB, Full, and Matlab.
\index{MARCA!output to}
The second argument is useful to name the resulting object in some formats
corresponding to programming languages (Python, Maple, R, Matlab, etc.).

\subsection{Implementations}

Transition structures implemented:
\begin{itemize}
  \item \code{TransitionStructure/SparseMatrix}
  \item \code{TransitionStructure/FullMatrix}
  \item {\tt TransitionStructure/HomogeneousMultidTransition} (generalized birth-death)
\end{itemize}
Projected:
\begin{itemize}
  \item \code{TransitionStructure/EventMixture}
  \item \code{TransitionStructure/QBD}
\end{itemize}

\subsubsection{\code{SparseMatrix}}
\label{sec:SparseMatrix}
\index{SparseMatrix@\code{SparseMatrix}!reference}

The class \code{SparseMatrix} implement sparse matrix storage, by rows. 

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteSparseMatrix.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} Four constructors are available:

\begin{quote}
\begin{verbatim}
SparseMatrix(int size);
SparseMatrix(int rowSize, int colSize);
SparseMatrix(MarmoteSet *space);
SparseMatrix(TransitionStructure* fullmat);
\end{verbatim}
\end{quote}
In the first one, the \code{size} parameter applies to the origin and the destination
space (square transition structures). In the second one, they are speficied separately.
By default, the origin and destination state spaces are created as
\code{MarmoteInterval()} objects.
In the third constructor, the state space is explicit and size of the matrix is deduced from its cardinal.
In the fourth constructor, the argument is another transition structure,
presumably full. The \code{SparseMatrix} object is created with the non-zero
elements of the argument.

\paragraph{Re-implemented methods.} The following methods have been re-implemented
in \code{SparseMatrix}:

\begin{quote}
\begin{verbatim}
  bool setEntry(int row, int col, double val);
  bool addToEntry(int row, int col, double val);
  double getEntry(int,int);
  int getNbElts(int row);
  int getCol(int row, int numCol );
  double getEntryByCol(int row, int numCol);
  DiscreteDistribution* TransDistrib(cardinalType row);
  double RowSum(int row);
  void EvaluateMeasureInPlace(double* m, double* res);
  void EvaluateMeasurePageRank(double* m, double* res, double alpha);
  DiscreteDistribution* EvaluateMeasure(DiscreteDistribution* d);
  void EvaluateValue(double* v, double* res);
  double EvaluateValueState(double* v, cardinalType stateIndex);
  SparseMatrix* Copy();
  SparseMatrix* Uniformize();
  SparseMatrix* Embed();
  SparseMatrix* Transpose();
  void Write(ostream* out, std::string modelname, std::string format);
\end{verbatim}
\end{quote}

The \code{Write()} method outputs the structure on some file
decriptor, using a given format (see
Appendix~\ref{chap:formats}). Supported formats are "Ers", "Full",
"MatrixMarket-sparse", "MatrixMarket-full", "Maple", "MARCA", "R",
"scilab" and "XBORNE".

\paragraph{Specific methods.}
Additional methods with respect to the top class are:

\begin{quote}
\begin{verbatim}
  bool addEntry(cardinalType row, cardinalType col, double val);
  void Normalize();
  SparseMatrix* Uniformize(double coeff);
  std::pair<std::vector<SCC>*, SparseMatrix*> getStronglyConnectedComponents(double ignore);
  void Diagnose(ostream* out);
  void FullDiagnose(ostream* out);
\end{verbatim}
\end{quote}

The \code{addEntry()} method inserts a new value in the matrix without checking
if an entry with the same row and column was already present. 

The \code{Normalize()} method reorganizes the internal storage of transitions
so that: a) no duplicate columns appear in rows; b) column numbers appear in
increasing order. The resulting structure makes some algorithms more efficient.

The \code{Uniformize(double)} method acts as \code{Uniformize()} but allows
to choose the uniformization factor, passed as argument.

The \code{getStronglyConnectedComponents()} method computes a decomposition
into strongly connected components of the graph of the matrix. The result
is returned as a pair $( \vec{C}, M )$. Here, $\vec{C}$ is the list of
strongly connected components, each being coded in a structure with
description:
\begin{quote}
\begin{verbatim}
  struct SCC {
    int id;  /**< index of the SCC */
    int period; /**< period of this SCC */
    std::set<int> states; /**< list of states indices in the SCC */
  };
\end{verbatim}
\end{quote}
The second part of the result, $M$, is the transition matrix between
these strongly connected components. The parameter \code{ignore} is
a threshold: entries with values less or equal to it are ignored in
the computation. The default value is 0.
The method applies to square transition structures, although this is
not currently enforced.

The \code{Diagnose()} method produces diagnostics and counts on the structure.
The \code{FullDiagnose()} method lists in addition the result of the
analysis of strongly connected components.

\subsubsection{\code{FullMatrix}}
\label{sec:FullMatrix}
\index{FullMatrix@\code{FullMatrix}!reference}

The class \code{FullMatrix} implement the usual full matrix storage, by rows. 

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteFullMatrix.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} Three constructors are available:

\begin{quote}
\begin{verbatim}
FullMatrix(int size);
FullMatrix(int rowSize, int colSize);
FullMatrix(MarmoteSet *space);
\end{verbatim}
% FullMatrix(TransitionStructure* fullmat);
\end{quote}
In the first one, the \code{size} parameter applies to the origin and the destination
space (square transition structures). In the second one, they are speficied separately.
By default, the origin and destination state spaces are created as
\code{MarmoteInterval()} objects.
In the third constructor, the state space is explicit and size of the matrix is deduced from its cardinal.

\paragraph{Re-implemented methods.} The following methods have been re-implemented
in \code{FullMatrix}:

\begin{quote}
\begin{verbatim}
  bool setEntry(int row, int col, double val);
  bool addToEntry(int row, int col, double val);
  double getEntry(int row, int col);
  int getNbElts(int row);
  int getCol(int row, int numCol );
  double getEntryByCol(int row, int numCol);
  DiscreteDistribution* TransDistrib(cardinalType row);
  double RowSum(int row);
  void EvaluateMeasureInPlace(double* m, double* res);
  void EvaluateMeasurePageRank(double* m, double* res, double alpha);
  DiscreteDistribution* EvaluateMeasure(DiscreteDistribution* d);
  void EvaluateValue(double* v, double* res);
  double EvaluateValueState(double* v, cardinalType stateIndex);
  FullMatrix* Copy();
  FullMatrix* Uniformize();
  FullMatrix* Embed();
  FullMatrix* Transpose();
  void Write(ostream* out, std::string modelname, std::string format);
\end{verbatim}
\end{quote}

The \code{Write()} method outputs the structure on some file
decriptor, using a given format (see
Appendix~\ref{chap:formats}). Supported formats are "Ers", "Full",
"MatrixMarket-sparse", "MatrixMarket-full", "Maple", "MARCA", "R",
"scilab" and "XBORNE".

\paragraph{Specific methods.}
Additional methods with respect to the top class are:

\begin{quote}
\begin{verbatim}
  FullMatrix* Uniformize(double coeff);
  void Diagnose(ostream* out);
\end{verbatim}
\end{quote}

The \code{Uniformize(double)} method acts as \code{Uniformize()} but allows
to choose the uniformization factor, passed as argument.

The \code{Diagnose()} method produces diagnostics and counts on the structure.

\begin{comment}
  %% Event Mixture currently not implemented in Marmote
  %% Pending...
\subsubsection{\code{EventMixture}}
\label{sec:EventMixture}
\index{EventMixture@\code{EventMixture}!reference}

The \code{EventMixture} class represents discrete-time transition structures
that are probabilistic mixtures of more elementary transition. The idea is that
transitions are governed by a finite set of ``events'', each occuring with a fixed
probability over time, and causing a fixed transition. 

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmote_event_mixture.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} Two constructors are available:

\begin{quote}
\begin{verbatim}
  EventMixture(int size,int nbEvents,double* probas,std::string* names,int** transitions );
  EventMixture(SparseMatrix* spMat);
\end{verbatim}
\end{quote}
The first constructor uses as arguments:
\begin{description}
\item[\code{size}] the size of the state space
\item[\code{nbEvents}] the number of different events
\item[\code{probas}] the respective probabilities of these events
\item[\code{names}] the respective names given to these events
\item[\code{transitions}] the array of elementary transitions corresponding to these events.
  Each of these array describes a mapping from one state to another one.
\end{description}

The second constructor extracts an event structure from a \code{SparseMatrix}
structure, in a greedy way (experimental).

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
       bool setEntry(int i, int j, double val);
       double getEntry(int i, int j);
       int getNbElts(int i);
       int getCol(int i, int k);
       double getEntryByCol(int i, int k);
       DiscreteDistribution* TransDistrib(int i);
       double RowSum(int i);
       EventMixture* Copy();
       EventMixture* Uniformize();
       EventMixture* Embed();
       void EvaluateMeasure(double* d, double* res) ;
       DiscreteDistribution* EvaluateMeasure(DiscreteDistribution* d);
       void EvaluateValue(double* v, double* res);
       void Write(ostream* out, std::string format);
\end{verbatim}
\end{quote}

The \code{Write()} method supports formats
XBORNE, MARCA, Ers, Maple and PSI3 (experimental).

\paragraph{Specific methods.}

\begin{quote}
\begin{verbatim}
      int nb_events();
      double event_proba(int e);
      double EvaluateValueState(double* v, int stateIndex);
\end{verbatim}
\end{quote}
The two first ones are accessors to the number of events and the
respective probabilies of these events.

The method \code{EvaluateValueState()} has the same function as \code{EvaluateValue()}
but returns the value for a single state passed as parameter \code{stateIndex}.
\end{comment}

\subsubsection{\code{HomogeneousMultidTransition}}
\label{sec:multidtransition}

The classe \code{HomogeneousMultidTransition} represents 
multidimensional, homogeneous random walk transition structures.
\begin{itemize}
\item the number of dimensions $d$,
\item the number of states in each dimension, assumed finite,
\item the probabilities to jump to the right in each dimension, ($p_1$, \ldots, $p_d$),
\item the probability to jump to the left in each dimension, ($q_1$, \ldots, $q_d$).
\end{itemize}
The model is valid if $\sum_{k=1}^d (p_i + q_i) \leq 1$.
The probability to stay at the same position is $r = 1 - \sum_{k=1}^d (p_i + q_i)$.
The boundaries are absorbing: when a transition goes out of bounds, it is assumed to stay
on the boundary.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteHomogenousMultidTransition.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class has a single constructor:

\begin{quote}
\begin{verbatim}
HomogeneousMultidTransition(timeType type, unsigned int nbDims, stateType* dim_size,
                            double* left_trans, double* right_trans);
\end{verbatim}
\end{quote}
The parameter \code{type} specifies whether the transition structure is in
continuous or discrete time.
The parameter \code{nbDims} is the number of dimensions $d$ and
the parameter \code{dimSize} specifies the extension in each dimension.
The process has $\times_{i=1}^d [0..n_i-1]$ as state space,
where the $n_i$ are the values in the array \code{dimSize}.
The arrays \code{left\_trans} and \code{right\_trans} will be interpreted
as jumping probabilities or rates, depending on the time type.
See Section \ref{sec:homogeneousMultiDRandomWalk} or
Section \ref{sec:homogeneousMultiDBirthDeath} for intepretations.

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
      bool setEntry(int i, int j, double val);
      double getEntry(int i, int j);
      int getNbElts(int i);
      int getCol(int i, int k);
      double getEntryByCol(int i, int k);
      DiscreteDistribution* TransDistrib(int i);
      double RowSum(int i);
      HomogeneousMultidTransition* Copy();
      HomogeneousMultidTransition* Uniformize();
      HomogeneousMultidTransition* Embed();
      HomogeneousMultidTransition* Transpose();
      void EvaluateMeasureInPlace(double* d,double* res);
      DiscreteDistribution* EvaluateMeasure(DiscreteDistribution* d);
      void EvaluateValue(double* v, double* res);
      void Write(ostream* out, string modelName, string format);
\end{verbatim}
\end{quote}

The \code{Write()} method supports formats
XBORNE, MARCA, Ers, Maple.

\paragraph{Specific methods.}

\begin{quote}
\begin{verbatim}
      int dim_size(int d);
      double p(int d);
      double q(int d);
      DiscreteDistribution* JumpDistribution();
\end{verbatim}
\end{quote}
The three first ones are accessors to the number of dimensions $d$ and the
probability vectors $p$ and $q$, corresponding to the constuctor of the class.

The method \code{JumpDistribution} returns
a discrete distribution representing the generic jumps.
The distribution has $2d + 1$ values: $ \{ 0, \pm 1, ..., \pm d \}$.
Assuming a numbering of dimensions from 1 to $d$, the coding is:
\begin{itemize}
\item 0 codes the self jump
\item $+i$ codes a jump upwards in dimension $i$
\item $-i$ codes a jump downwards in dimension $i$.
\end{itemize}


\section{The \code{MarmoteSet} object}
\label{sec:MarmoteSet}
\index{MarmoteSet@\code{MarmoteSet}!reference}

In \marmotecore, sets are represented by unions of discrete (hyper-)rectangles.
The simplest set is an integer interval. Other sets are constructed from
cartesian products of such intervals, and unions of them.

\subsection{Common features}

Methods common to all \code{MarmoteSet} objects are summarized
in the following tables.

States are represented by arrays of integers.
A special type is used for states:
\begin{description}
\item[MarmoteState]: the type representing a state, that is, a member of
  some \code{MarmoteSet} object. It is currently implemented as
  an array of \code{cardinalType} but it is discouraged to rely on this
  assumption.
\end{description}

\index{MarmoteState@\code{MarmoteState}!reference}

\subsubsection{Definition}

This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteSet.h"
\end{verbatim}
\end{quote}

\subsubsection{Attributes and accessors}

All \code{MarmoteSet} objects have the following common attributes:
\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
    enum opType & { UNION, PRODUCT, SIMPLE } & \rm specify the type
    of construction \\
    int & nb\_dimensions\_ & \rm number of dimensions for products \\
    int & nb\_zones\_ & \rm number of subsets for unions \\
    stateType & cardinal\_ & \rm total cardinal \\
    MarmoteSet** & zone\_ & \rm array of subsets for unions \\
    MarmoteSet** & dimension\_ & \rm array of dimensions for products \\
    MarmoteState & state\_buffer\_ & \\
%%%% hiding protected attributes: only for developers
%    int* & dim\_offset\_ & \\
%    int* & idx\_offset\_ & \\
%    int  & tot\_nb\_dims\_ & \\
%    int* & first\_state\_ & \rm value of the state indexed 0 \\
  \hline
  \end{tabular}
\end{center}

\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
    \multicolumn{3}{l}{// accessors} \\
    long int & Cardinal() & \rm number of elements in the set \\
    bool & IsFinite() & \\
    bool & IsSimple() & \\
    bool & IsUnion() & \\
    bool & IsProduct() & \\
    int & tot\_nb\_dims() & \rm number of dimensions for products \\
    \hline
\end{tabular}
\end{center}

\subsubsection{Constructors}

\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
    \multicolumn{3}{l}{// constructors} \\
    & MarmoteSet() & \\
    & \multicolumn{2}{l}{MarmoteSet( MarmoteSet **list, unsigned int nb, opType t )} \\
    \hline
\end{tabular}
\end{center}

The simple \code{MarmoteSet()} initializes
a set with the minimal features corresponding to an empty set. The user
is responsible for setting up the attributes of the set. This is normally
used only in derived classes.

The constuctor \code{MarmoteSet( MarmoteSet **list, int nb, opType t )}
builds a set from more elementary ones, using the construction of type
\code{t} given as argument. The type may be one of \code{UNION} or \code{PRODUCT}.
The number of subsets is \code{nb} and they are provided in the array \code{list}.

\subsubsection{State representation and indexing}

\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
    \multicolumn{3}{l}{// state-index conversions} \\
    void & DecodeState(int index, MarmoteState); \\
    int & Index(MarmoteState) & \\
    \hline
\end{tabular}
\end{center}

For computational purposes, all states are represented by a vector (array) of integers.
The number of elements in this array is the ``total dimension'' of the set,
stored in the attribute \code{tot\_nb\_dims\_} and can be retrieved with the accessor
\code{tot\_nb\_dims()}. However, most objects like
transition structures and distributions require that the elements of the set be represented
as consecutive integers. Any \code{MarmoteSet} class must then implement a one-to-one
correspondence between its states and some numbers called the \textit{indices} of the
states.\footnote{When no confusion can occur, states and their indices are
  assimilated in this manual.}

The two methods performing this conversion are \code{Index()} to pass from
a state to an index, and \code{DecodeState()} to do the reverse.
These methods are used very often and should be as efficient as possible.

\subsubsection{Walking through sets}

Walking through sets is performed using the following methods.

\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
    \multicolumn{3}{l}{// state space exploration} \\
    void & FirstState(MarmoteState) & \\
    void & NextState(MarmoteState) & \\
    bool & IsFirst(MarmoteState) & \\
    \hline
\end{tabular}
\end{center}

An elementary operation on sets is to consider all states sequentially.
For this purpose, every \code{MarmoteSet} object identifies a
particular state called the ``first'' or ``initial'' state, and stored in
the attribute \code{first\_state\_}. This is usually the state with index 0 but
need not be so.

In addition, \code{MarmoteSet} provides three functions:
\begin{description}
\item[initialization] with \code{FirstState(stateBuffer)}, which sets
  the state (represented in the array \code{stateBuffer} to the first
  state of the state space;
\item[increment] of the state with \code{NextState(stateBuffer)}, which
  moves the state to the next one in the enumeration order;
\item[termination test] with \code{IsFirst(stateBuffer)} which tests
  whether the enumeration came back to the initial state.
\end{description}

\subsubsection{I/O}

I/O methods related to states and set are the following:

\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
    \multicolumn{3}{l}{// I/O utilities} \\
    void & enumerate() & \\
    void & PrintState(ostream* out, int index); & \\
    \hline
\end{tabular}
\end{center}

The \code{Enumerate()} utility walks through the state space using the
three constructs decribed above, printing each state in the process.

The method \code{PrintState()} writes a representation of the state to the
stream passed as parameter.

There are currently no provision for reading or writing state spaces as a whole.

\subsection{Implementations}

Six sets or classes of sets are currently implemented:
\begin{center}
\begin{tabular}{lll}
  Name & description & inherits from \\
  \hline
  \code{EmptySet} & the empty set &
  \code{MarmoteSet} \\
  \code{MarmoteInterval} & a simple 1-dimensional discrete interval, possibly infinite &
  \code{MarmoteSet} \\
  \code{Integers} & the set of all integers &
  \code{MarmoteInterval} \\
  \code{MarmoteBox} & cartesian products of intervals &
  \code{MarmoteSet} \\
  \code{BinarySequence} & sequences of bits &
  \code{MarmoteSet} \\
  \code{BinarySimplex} & sequences of bits with given count of ones &
  \code{MarmoteSet} \\
  \code{Simplex} & sequences of integers with given total sum &
  \code{MarmoteSet} \\
  \hline
\end{tabular}
\end{center}

\subsubsection{\code{EmptySet}}
\index{EmptySet@\code{EmptySet}!reference}

This class implements the empty set.
It is intended primarily as an exercise, but can also be used as a default
value or a place-holder in some cases.

\paragraph{Definition.} This class is accessed with the directive

\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteEmptySet.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class has a single constructor:

\begin{quote}
\begin{verbatim}
EmptySet();
\end{verbatim}
\end{quote}

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
bool IsFinite();
bool Belongs(MarmoteState);     
bool IsFirst(MarmoteState);
void FirstState(MarmoteState);
void NextState(MarmoteState);
void DecodeState(int index, MarmoteState);
int Index(MarmoteState);
void PrintState(ostream* out, MarmoteState);
void enumerate();
\end{verbatim}
\end{quote}

Method \code{IsFinite()} returns \code{true}. Method \code{Belongs()} returns
\code{false}, since there are no states in the set. Likewise for
\code{IsFirst()}. The other methods issue error messages and do nothing.
Method \code{Index()} returns 0 by convention.

\paragraph{Specific methods.} The class does not provide specific methods,
except for \code{Copy()}.

\subsubsection{\code{MarmoteInterval}}
\index{MarmoteInterval@\code{MarmoteInterval}!reference}

This class implements sets of the form $\{ a, a+1, \ldots, b \}$ where
$a$ and $b$ are integers. The cardinal of the set is $b - a + 1$,
provided that $a\leq b$. Sets of this class are always finite.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteInterval.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class has a single constructor:

\begin{quote}
\begin{verbatim}
       MarmoteInterval( int min, int max );
\end{verbatim}
\end{quote}
By convention, if $\code{max} < \code{min}$, then the
interval is empty. Otherwise, both \code{min} and \code{max} are inside the interval.

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
      bool IsFinite();
      bool IsFirst(MarmoteState);
      void FirstState(MarmoteState);
      void NextState(MarmoteState);
      void DecodeState(int index, MarmoteState);
      int Index(MarmoteState);
      void PrintState(ostream* out, MarmoteState);
      void enumerate();
\end{verbatim}
\end{quote}
The first state is set as $a$. The index of state $s$ is $s-a$.

The \code{PrintState()} method writes the state value with a leading
white space and a minimal formating width equal to 4 characters.

\paragraph{Specific methods.} The class does not provide specific methods.
In particular, the values of $a$ and $b$ cannot be directly accessed after the creation
of the object.

%% \begin{quote}
%% \begin{verbatim}
%% \end{verbatim}
%% \end{quote}

\subsubsection{\code{MarmoteIntegers}}
\index{Integers@\code{MarmoteIntegers}!reference}

This class implements the set of all natural integers $\N = \{ 0, 1, 2, \ldots \}$.
It is a particular case of \code{MarmoteInterval}, from which it inherits.

\paragraph{Definition.} This class is accessed with the directive

\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteIntegers.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class has a single constructor:

\begin{quote}
\begin{verbatim}
MarmoteIntegers();
\end{verbatim}
\end{quote}

\paragraph{Re-implemented methods.}

The following methods are reimplemented from \code{MarmoteInterval}:

\begin{quote}
\begin{verbatim}
bool IsFinite();
bool Belongs(MarmoteState);  
\end{verbatim}
\end{quote}

Method \code{IsFinite()} returns false.

\paragraph{Specific methods.} The class does not provide specific methods,
except for \code{Copy()}.

\subsubsection{\code{MarmoteBox}}
\label{sec:MarmoteBox}
\index{MarmoteBox@\code{MarmoteBox}!reference}

The \code{MarmoteBox} class represents ``rectangular'' sets.
They are cartesian products of one-dimensional intervals:
$\times_{i=1}^d [a_b..b_i]$. They are not implemented using
the \code{MarmoteInterval} objects however.
These sets \textit{may be infinite}.
\index{infinite state space!in MarmoteBox@\code{MarmoteBox}}

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteBox.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class provides two constructors:

\begin{quote}
\begin{verbatim}
       MarmoteBox(int nbDims, int* dimSize);
       MarmoteBox(int nbDims, int *lower, int* upper);
\end{verbatim}
\end{quote}
In both, the parameter \code{nbDims} specifies the dimension $d$. It must be larger than
1 although this condition is not currently enforced.

In the first variant, the array \code{dimSize}, which must have $d$
elements, contains the sizes of the different dimensions. These
numbers may be \code{INFINITE\_STATE\_SPACE\_SIZE}, in which case the corresponding dimension
will be considered as \N, or a finite value $n$, in which case the dimension
will be considered as the interval $\{ 0, \ldots, n-1 \}$.

In the second variant, the values $a_i$ and $b_i$ are provided in the arrays
\code{lower} and \code{upper}. These must be \textit{nonnegative} values, or
\code{INFINITE\_STATE\_SPACE\_SIZE}. By convention, if $a_i > b_i$, the interval
of the corresponding dimension is assumed to be $\{ a_i \}$.

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
      bool IsFinite();
      bool IsFirst(MarmoteState);
      void FirstState(MarmoteState);
      void NextState(MarmoteState);
      void DecodeState(int index, int* buf);
      int Index(int* buf);
      void PrintState(ostream* out, MarmoteState);
\end{verbatim}
\end{quote}

The first state is set as $(a_1,\ldots,a_d)$. States are ordered lexicographically
so that the index of state $(s_1,\ldots,s_d)$ is given by the formula:
\begin{displaymath}
  \code{index}(s_1,\ldots,s_d)
  ~ = ~
  \sum_{i=1}^d s_i ~ \prod_{j=i+1}^{d} (b_j-a_j+1)
  ~.
\end{displaymath}

The \code{PrintState()} method writes the state value as a sequence of numbers
between parentheses and separated by commas, each number having a leading
white space and a minimal formating width equal to 3 characters.
Example: \code{(\ \ \ 3, 150, \ 20)}.

\paragraph{Specific methods.} The class does not provide specific methods.
In particular, the values of used for creating the object cannot be
directly accessed after the creation.

%% \begin{quote}
%% \begin{verbatim}
%% \end{verbatim}
%% \end{quote}

\subsubsection{\code{BinarySequence}}
\label{sec:BinarySequence}
\index{BinarySequence@\code{BinarySequence}!reference}

The \code{BinarySequence} class represents sequences (or words) of bits.
They can be seen as cartesian powers of the set $\{ 0, 1 \}$
and therefore as rectangular sets. 
They are not implemented using
the \code{MarmoteBox} objects however.
These sets are always finite.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteBinarySequence.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class has a single constructor:

\begin{quote}
\begin{verbatim}
      BinarySequence(int n);
\end{verbatim}
\end{quote}
The parameter \code{n} is the length of the sequence. The set has then $2^n$ states.

\paragraph{Re-implemented methods.} The following methods are re-implemented in the class:

\begin{quote}
\begin{verbatim}
      bool IsFinite();
      bool IsFirst(MarmoteState);
      void FirstState(MarmoteState);
      void NextState(MarmoteState);
      void DecodeState(int index, int* buf);
      int Index(int* buf);
      void PrintState(ostream* out, MarmoteState);
\end{verbatim}
\end{quote}
The first state is the sequence $(0,\ldots,0)$. States are ordered lexicographically
so that the index of state $(s_1,\ldots,s_d)$ is given by the formula:
\begin{displaymath}
  \code{index}(s_1,\ldots,s_d)
  ~ = ~
  \sum_{i=1}^d s_i ~ 2^{d-i}
  ~.
\end{displaymath}

The \code{PrintState()} method writes the state value as a sequence of bits
(0 or 1) between parentheses and separated by white spaces.
Example: \code{( 1 1 1 0 0 0 1 0 1 )}.

\paragraph{Specific methods.} The class does not provide specific methods.
In particular, the value \code{n} used for creating the object cannot be
directly accessed after the creation.

%% \begin{quote}
%% \begin{verbatim}
%% \end{verbatim}
%% \end{quote}

\subsubsection{\code{BinarySimplex}}
\label{sec:BinarySimplex}
\index{BinarySimplex@\code{BinarySimplex}!reference}

The \code{BinarySimplex} class represents sequences (or words) of bits
in which the number of ones is constant. Formally,
\begin{displaymath}
  \mathcal{S}_{n,p} := 
  \{ \sigma \in \{0,1\}^n, |\sigma|_1 = p \}.
\end{displaymath}
These sets are always finite, with cardinal $\binom{n}{p}$.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteBinarySimplex.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class provides a single constructor:

\begin{quote}
\begin{verbatim}
      BinarySimplex(int n, int p);
\end{verbatim}
\end{quote}
The parameter \code{n} specifies the length of the sequence, and \code{p}
specifies the number of ones. It is required that $0 \leq p \leq n$,
although this condition is not currently enforced.

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
      bool IsFinite();
      bool IsFirst(MarmoteState);
      void FirstState(MarmoteState);
      void NextState(MarmoteState);
      void DecodeState(int index, int* buf);
      int Index(int* buf);
      void PrintState(ostream* out, MarmoteState);
\end{verbatim}
\end{quote}

The first state is the sequence $(1,\ldots,1,0,\ldots,0)$ where the $p$ ones
are leading the sequence. States are ordered lexicographically
\textit{with letter order 1 < 0}.
The index of state $(s_1,\ldots,s_n)$ is given by the recursive formula:
\begin{displaymath}
  \code{index}(n,p;s_1,\ldots,s_n)
  ~ = ~
  \left\{ \begin{array}{ll}
    \code{index}(n-1,p-1;s_2,\ldots,s_n) & \text{if $s_1 = 1$} \\
    \\
  \displaystyle\binom{n-1}{p-1} + \code{index}(n-1,p;s_2,\ldots,s_n)
  & \text{if $s_1 = 0$}
  \end{array}
  \right.
\end{displaymath}
with the boundary condition $\code{index}(n,0;0,\ldots,0) = 0$.

The \code{PrintState()} method writes the state value as a sequence of bits
(0 or 1) between parentheses and separated by white spaces.
Example: \code{( 1 1 1 0 0 0 1 0 1 )}.

\paragraph{Specific methods.} The class does not provide specific methods.
In particular, the values \code{n} and \code{p} used for creating the object cannot be
directly accessed after the creation.

\subsubsection{\code{Simplex}}
\label{sec:simplex}
\index{Simplex@\code{Simplex}!reference}

The \code{Simplex} class represents sequences of nonnegative integer numbers
with a given total sum. Formally,
\begin{displaymath}
  \mathcal{S}_{n,p} := 
  \{ \sigma \in \N^n, \sum_{i=1}^{n} \sigma_n = p \}.
\end{displaymath}
These sets are always finite, with cardinal: $\binom{n+p-1}{n-1}$.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteSimplex.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class provides a single constructor:

\begin{quote}
\begin{verbatim}
      Simplex(int n, int p);
\end{verbatim}
\end{quote}
The parameter \code{n} specifies the length of the sequence, and \code{p}
specifies the total sum. 

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
bool IsFinite();
void DecodeState(int index, int* buf);
int Index(int* buf);
void PrintState(ostream* out, MarmoteState);
\end{verbatim}
\end{quote}

The first state is the sequence $(0,0,\ldots,0,p)$.
States are ordered lexicographically.
That the index of state $(s_1,\ldots,s_n)$ is given by the recursive formula:
\begin{displaymath}
  \code{index}(n,p;s_1,\ldots,s_n)
  ~ = ~
  \left\{ \begin{array}{ll}
    0 & \text{if $n = 1$} \\
    \\
    L( s_1, n, p ) + \code{index}(n-1,p-s_1;s_2,\ldots,s_n)
    & \text{if $n \geq 2$}
  \end{array}
  \right.
\end{displaymath}
where
\begin{displaymath}
  L( j, n, p ) ~ = ~ \sum_{i=0}^{j-1} \binom{p-i+k-2}{k-2}
  ~.
\end{displaymath}

The \code{PrintState()} method writes the state value as a sequence of
numbers between parentheses and separated by white spaces.
Example: \code{( 1 4 1 0 0 0 7 0 1 )}.

\paragraph{Specific methods.} The class does not provide specific methods.
In particular, the values \code{n} and \code{p} used for creating the object cannot be
directly accessed after the creation.

%% \begin{quote}
%% \begin{verbatim}
%% \end{verbatim}
%% \end{quote}

\section{The \code{Distribution} object}
\label{sec:Distribution}
\index{Distribution@\code{Distribution}!reference}

\subsection{Common features}
\label{sec:distribution-features}

\subsubsection{Definition}

This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteDistribution.h"
\end{verbatim}
\end{quote}

\subsubsection{Constants and types}

Some constants are specifically defined for \code{Distribution} objects.

\begin{description}
\item[\code{distType}]: type of distances between distributions;
  existing values are \code{DISTANCE\_L1}, \code{DISTANCE\_L2},
  \code{DISTANCE} \code{\_LINFINITY}, \code{DISTANCE\_TV} (for the total variation distance);
  \index{distance!between distributions}

\item[\code{INFINITE\_DURATION}]: representation of infinity, in the case
  where some moments of the distribution can be infinite;
  \index{infinity (numerical representation)!\code{INFINITE\_DURATION}}
  
\item[\code{INFINITE\_RATE}]: representation of infinity, in the case where
  the ``rate'' is a meaningful concept for the distribution, and its
  mathematical value is infinity (inverse of 0).
  \index{infinity (numerical representation)!\code{INFINITE\_RATE}}
\end{description}

\subsubsection{Attributes and accessors}

\code{Distribution} objects have one common attribute:

\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
  double & 		mean\_ & \rm the mathematical expectation of the distribution \\
    \hline
  \end{tabular}
\end{center}

The methods common to \code{Distribution} objects are 
summarized in the following table.

\begin{center}
  \tt
  \begin{tabular}{lll}
    \hline
  double	& Mean() & \rm mathematical expectation \\
  double	& Rate() & \rm inverse of the mean \\
  double	& Moment(int n) & \rm $n$-th moment \\
  double	& Variance(); & \rm variance \\
  double	& Laplace(double s) & \rm Laplace transform evaluated at real $s$ \\
  double	& DLaplace(double s) & \rm derivative of the Laplace transform \\
  double	& Cdf(double x) & \rm cumulative distribution function \\
  double	& Ccdf(double x) & \rm complementary cumulative distribution function \\
  bool		& HasMoment(int n) & \rm check that moments exist \\
  Distribution* & Rescale(double factor) & \rm scaling the distribution by a real factor \\
  Distribution* & Copy() & \\
  double	& Sample() & \rm generate a pseudo-random sample from the distribution \\
  void		& IidSample(int n, double* s) & \rm generate several samples \\
  double	& Distance(distType, Distribution*, & \rm compute some distance for distributions \\
                & \qquad\qquad\quad Distribution*) & \\
  bool		& HasProperty(std::string) & \rm tests whether the distribution has some property \\
  \hline
\end{tabular}
\end{center}

The \code{Cdf()} and \code{Ccdf()} methods return respectively, for
$x$ supplied as argument:
\begin{displaymath}
  F_X(x) := P( X \leq x ) \qquad P( X > x ) = 1 - F_X(x).
\end{displaymath}

The \code{Distance()} method accepts as argument any of the \code{distType} constants
listed above. 
In addition to this generic \code{Distance()} method, some shorthand forms exist for the
four distances of the \code{distType} type:
\begin{center}
\code{DistanceL1(Distribution*,Distribution*)},
\code{DistanceL2(Distribution*,Distribution*)},\\
\code{DistanceLInfinity(Distribution*,Distribution*)},
\code{DistanceTV(Distribution*,Distribution*)}.
\end{center}
Not all distances are defined for all distributions, and even when defined,
not all are implemented. 

The \code{HasProperty()} method tests if the distribution has one of the following properties:
\code{"integerValued"},
\code{"compactSupport"},
\code{"continuous"},
\code{"discrete"},
\code{"discreteFinite"}.

\subsection{Implementations}

The following distributions are implemented:
\begin{center}
  \small
\begin{tabular}{lll}
  Name & description & inherits from \\
  \hline
  \tt DiscreteDistribution & finite discrete distribution & \tt Distribution \\
  \tt DiracDistribution & Dirac mass & \tt DiscreteDistribution \\
  \tt BernoulliDistribution & Bernoulli distribution & \tt DiscreteDistribution \\
  \tt UniformDiscreteDistribution & uniform distribution over integer intervals & \tt DiscreteDistribution \\
  \tt ShiftedGeometricDistribution & geometric distribution over $\{a,a+1,\dots\}$ &
  \tt DiscreteDistribution \\
  \tt GeometricDistribution & geometric distribution over \N & \tt ShiftedGeometricDistribution \\
  \tt PoissonDistribution & Poisson distribution & \tt DiscreteDistribution \\
  \tt PhaseTypeDiscreteDistribution & discrete phase-type distribution & \tt DiscreteDistribution \\
  \tt GammaDistribution & Gamma distribution & \tt Distribution \\
  \tt ErlangDistribution & Erlang distribution & \tt GammaDistribution \\
  \tt ExponentialDistribution & negative exponential distribution & \tt ErlangDistribution \\
  \tt GaussianDistribution & univariate gaussian distribution & \tt Distribution \\
  \tt UniformDistribution & uniform continuous distribution & \tt Distribution \\
  \tt PhaseTypeDistribution & continuous phase-type distribution & \tt Distribution \\
  \hline
\end{tabular}
\end{center}

\subsubsection{\code{DiscreteDistribution}}
\label{sec:DiscreteDistribution}
\index{DiscreteDistribution@\code{DiscreteDistribution}!reference}

This is the general discrete distribution. It represents a discrete list of
$n$ \textit{values} $v_1,\ldots,v_n$ and a list of $n$ probabilities
$p_1,\ldots,p_n$. The implementation of the list of values may be:
either as an actual table of values, or as a \code{MarmoteSet}.
Likewise, the list of probabilities may be:
either as an actual table of real numbers, or implicit (especially in
derived classes representing specific families of distributions).

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteDiscreteDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class provides three constructors.

\begin{quote}
\begin{verbatim}
  DiscreteDistribution( stateType sz, double* vals, double* probas );
  DiscreteDistribution( MarmoteSet* space, double* probas );
  DiscreteDistribution( stateType sz, std::string filename );
\end{verbatim}
\end{quote}
The first one creates the object from existing tables of values and probabilities.
These arrays must be (at least) of size \code{sz}. They are \textit{copied}
in the object that is created.
It is \textit{not} assumed that the values $v_i$ are distinct, nor ordered.

The second constructor creates the object as above, but with values specified
as a \code{MarmoteSet}. The array of probabilities is also copied at creation.

The third constructor reads the distribution
from the file which name is provided as argument \code{name}. The file should
consist in \code{sz} real numbers, one per line. They should be positive and
add up to 1.0, although this is not currently enforced. If anything goes wrong
with the file (not accessible, too short, ...) missing probabilities are assumed
to be 0. The values are implicitly assume to be 0, 1, ..., \code{sz-1}.

All constructors calculate and store the expectation of the distribution.

\paragraph{Re-implemented methods.} The following methods are re-implemented
in the class.

\begin{quote}
\begin{verbatim}
  double    Mean();
  double    Moment( int order );
  double    Cdf( double x );
  bool      HasMoment( int order );
  DiscreteDistribution *Rescale( double factor );
  DiscreteDistribution *Copy();
  double    Sample();
\end{verbatim}
\end{quote}

These distributions have moments of any order: the method \code{HasMoment()} always
returns \code{true}. Rescaling by a factor $f$ produces a distribution on
values $f\times v_1,\ldots,f\times v_n$ and the same probabilities.
The \code{Sample()} produces a pseudo-random sample of the distribution. It uses
a simple linear algorithm and may be inefficient for large values of $n$.

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
      int       nb_vals();
      double*   values();
      double*   probas();
      double    getProbaByIndex(int i);
      double    getProba(double value);
      double    getValue(int i);
      bool      setProba(int i, double v);
      double    distanceL1( DiscreteDistribution* d );
      double    distanceL2( DiscreteDistribution* d );
      double    distanceLinfinity( DiscreteDistribution* d );
      void      Write( ostream *out, int mode );
\end{verbatim}
%      std::string toString();
\end{quote}
Methods \code{nb\_vals()}, \code{values()} and \code{probas()} are accessors
to $n$ and the tables of values and probabilities, respectively.

Method \code{getProbaByIndex()} returns $p_i$ where $i$ is specified by \code{i}.
The user has no control on the order of the entries. This method is normally used to
browse through all probabilities. Method \code{getValue()} returns $v_i$ where
$i$ is given by parameter \code{i}. A \textit{tolerance} of $10^{-8}$ is applied to the
parameter \code{value}.

Method \code{getProba()} returns the probability
of the value \code{v}. Since values $v_i$ are not necessarily distinct, this is
computed as $\sum\{ p_j | v_j = v \}$. This method may be inefficient for large
values of $n$.

Method \code{setProba()} allows to change the value $p_i$ where $i$ is spefified
as arguement. The resulting object is not necessarily a distribution anymore.
Its mean is incorrect. To be used with caution (or not at all).

The methods \code{DistanceL1()}, \code{DistanceL2()} and \code{DistanceLinfinity()}
compute respectively:
\begin{displaymath}
  \sum_{i=1}^n |p_i - p'_i|,
  \qquad
  \sqrt{\sum_{i=1}^n |p_i - p'_i|^2},
  \qquad
  \max\left\{ |p_i - p'_i|, 1 \leq i \leq n \right\}.
\end{displaymath}
They all \textit{assume implicitly that the set of values is the same} for
the distributions that are compared.

The \code{Write()} method prints a representation of the distribution on file
descriptor \code{out} with format specified as \code{mode}. Available formats
are \code{DEFAULT\_PRINT\_MODE} and \code{MAPLE\_PRINT\_MODE}.
They produce respective results as:
\begin{verbatim}
      discrete [ v1 v2 ... vn ] [ p1 p2 ... pn ]
      Vector( [ p1, p2, ..., pn ] );
\end{verbatim}

\subsubsection{\code{DiracDistribution}}
\label{sec:DiracDistribution}
\index{DiracDistribution@\code{DiracDistribution}!reference}

This is the Dirac distribution, concentrated at some value $v$.
It is a special case of finite discrete distribution and the class
inherits from \code{DiscreteDistribution}.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteDiracDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} There is only one constructor to this class:

\begin{quote}
\begin{verbatim}
      DiracDistribution( double val )
\end{verbatim}
\end{quote}

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
      double	Mean();
      double	Rate(); 
      double	Moment( int order );
      double	Variance();
      double	Laplace( double s );
      double	DLaplace( double s );
      double	Cdf( double x );
      bool	HasMoment( int order );
      DiracDistribution *Rescale( double factor );
      DiracDistribution *Copy();
      double	Sample();
      void	IidSample( int n, double* s );
      double    getProba(double value);
      void Write( ostream* out, int mode );
\end{verbatim}
%      std::string toString();
\end{quote}
These distributions have moments of any order: the method \code{HasMoment()} always
returns \code{true}. Rescaling by a factor $f$ produces a Dirac distribution on
value $f\times v$.

Methods \code{getProba()} and \code{Write()}
reimplement the methods from \code{DiscreteDistribution}.
The last one writes "\code{Dirac distribution at} $v$" whatever the
format specified.

\paragraph{Specific methods.}

The following method is specific to the class:
\begin{quote}
\begin{verbatim}
      double  value(int);
\end{verbatim}
\end{quote}
It is an accessor for $v$.

\subsubsection{\code{BernoulliDistribution}}
\label{sec:BernoulliDistribution}
\index{BernoulliDistribution@\code{BernoulliDistribution}!reference}

This is the Bernoulli distribution with parameter $p$.
It is the distribution $\{0,1\}$ with probabilities $p$ and $1-p$.
It is a special case of finite discrete distribution and the class
inherits from \code{DiscreteDistribution}.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteBernoulliDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class has a single constructor:

\begin{quote}
\begin{verbatim}
      BernoulliDistribution( double val );
\end{verbatim}
\end{quote}
Its parameter is the probability $p$.

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
  double	Mean();
  double	Rate(); 
  double	Moment( int order );
  double	Cdf( double x );
  bool		HasMoment( int order );
  BernoulliDistribution *Rescale( double factor );
  BernoulliDistribution *Copy();
  double	Sample();
  void Write( ostream* out, int mode );
\end{verbatim}
%  std::string toString();
\end{quote}
These distributions have moments of any order: the method \code{HasMoment()} always
returns \code{true}. Rescaling is not possible and returns a copy of the original
distribution.

Method \code{Write()}
reimplement the method from \code{DiscreteDistribution}.
It writes "\code{Bernoulli distribution with proba} $p$"
whatever the mode specified.

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
  double	getParameter();
  double	proba();
\end{verbatim}
\end{quote}
Both methods \code{getParameter()} and \code{proba()} are accessors to the parameter
$p$.

\subsubsection{\code{UniformDiscreteDistribution}}
\label{sec:UniformDiscreteDistribution}
\index{UniformDiscreteDistribution@\code{UniformDiscreteDistribution}!reference}

This is the uniform distribution over some integer interval $a..b = \{a, a+1, \ldots, b-1, b \}$.
It is a special case of finite discrete distribution and the class
inherits from \code{DiscreteDistribution}.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteUniformDiscreteDistribution.h"
\end{verbatim}
\end{quote}


\paragraph{Constructors.} The class has a single constructor:

\begin{quote}
\begin{verbatim}
UniformDiscreteDistribution( int valInf, int valSup );
\end{verbatim}
\end{quote}
It defines the values of $a$ and $b$ by parameters \code{valInf} and \code{valSup}
respectively. It is necessary that $a \leq b$ although this is not currently
enforced.

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
  double	Mean();
  double	Rate(); 
  double	Moment( int order );
  double	Laplace( double s );
  double	DLaplace( double s );
  double	Cdf( double x );
  double	Ccdf( double x );
  bool		HasMoment( int order );
  PhaseTypeDistribution *Rescale( double factor );
  PhaseTypeDistribution *Copy();
  double	Sample();
  void		IidSample( int n, double* s );
  double getProba(double value);
  void Write( ostream* out, int mode );
\end{verbatim}
%  std::string toString();
\end{quote}
These distributions have moments of any order: the method
\code{HasMoment()} always returns \code{true}. Rescaling is not
possible and returns a copy of the original distribution.

Method \code{Write()}
reimplement the method from \code{DiscreteDistribution}.
It writes "\code{uniform distribution on} [$a$..$b$]"
whatever the mode specified.

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
  int	valInf();
  int	valSup();
\end{verbatim}
\end{quote}
They give access to the parameters $a$ and $b$ respectively.

\subsubsection{\code{ShiftedGeometricDistribution}}
\label{sec:ShiftedGeometricDistribution}
\index{ShiftedGeometricDistribution@\code{ShiftedGeometricDistribution}!reference}

This is the geometric distribution on the set $\{ a, a+1, \ldots \}$
where $a\in\N$.  It has two parameters: an integer offset $a$ which is
the smallest value the random variable can take, and a probability
$p$, interpreted as the probability that $X$ is \textit{strictly}
larger than $a$. In other words, the distribution is:
\begin{displaymath}
  P( X = k ) ~ = ~ (1-p) ~ p^{k-a}, \quad k\in\N, k\geq a.
\end{displaymath}
The value $p=1$ is accepted, in which case the distribution is interpreted as
a Dirac mass at infinity. Its mean and higher moments are then infinite.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteShiftedGeometricDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class has a single constructor,

\begin{quote}
\begin{verbatim}
      ShiftedGeometricDistribution( long int offset, double p );
\end{verbatim}
\end{quote}
which sets the parameters $a$ (the ``offset'') and $p$.

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
  double 	getProbaByIndex(cardinalType idx);
  double 	getProba(double k);
  double	Mean();
  double	Rate();
  double	Moment( int order );
  double	Variance( int order );
  double	Laplace( double s );
  double	DLaplace( double s );
  double	Cdf( double x );
  bool		HasMoment( int order );
  GeometricDistribution *Rescale( double factor );
  GeometricDistribution *Copy();
  double	Sample();
  void 		Write( ostream* out, int mode );
\end{verbatim}

% std::string toString();
\end{quote}
These distributions have moments of any order, except when $p=1$.
Rescaling is not possible and returns a copy of the original
distribution.
Method \code{Write()} is available only for default format
\code{FORMAT\_MARMOTE} and writes
"\code{ShiftedGeometric on [}$a$\code{..+oo) with proba }$p$\code{: P(k) = }$(1-p)$\code{ x (}$p$\code{)\^{}(k-}$a$\code{) k=}$a$\code{..+oo}".

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
  long int 	offset();
  double 	p();
  double 	getRatio();
\end{verbatim}
\end{quote}
The method \code{offset()} gives access to the parameter $a$. Observe that
its return type is \code{double}.
Both methods \code{p()} and \code{getRatio()} give access to the parameter $p$.
Methods \code{getProba()} returns the probability $P(X=k)$.

\subsubsection{\code{GeometricDistribution}}
\label{sec:GeometricDistribution}
\index{GeometricDistribution@\code{GeometricDistribution}!reference}

This is the geometric distribution on \N. It has one parameter, a probability $p$,
interpreted as the probability that $X$ is \textit{not} 0. In other words, the
distribution is:
\begin{displaymath}
  P( X = k ) ~ = ~ (1-p) ~ p^k, \quad k\in\N.
\end{displaymath}
The value $p=1$ is accepted, in which case the distribution is interpreted as
a Dirac mass at infinity. Its mean and higher moments are then infinite.

Since it is a particular case of \code{ShiftedGeometricDistribution} with offset
$a=0$, the class inherits from it.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteGeometricDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class has a single constructor,

\begin{quote}
\begin{verbatim}
      GeometricDistribution( double p );
\end{verbatim}
\end{quote}
which sets the parameter $p$.

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
  double 	getProbaByIndex(cardinalType idx);
  double 	getProba(double k);
  double	Mean();
  double	Rate();
  double	Moment( int order );
  double	Variance( int order );
  double	Laplace( double s );
  double	DLaplace( double s );
  double	Cdf( double x );
  bool		HasMoment( int order );
  GeometricDistribution *Rescale( double factor );
  GeometricDistribution *Copy();
  double	Sample();
  void 		Write( ostream* out, int mode );
\end{verbatim}
% std::string toString();
\end{quote}
These distributions have moments of any order, except when $p=1$.
Rescaling is not possible and returns a copy of the original
distribution.
Method \code{Write()} accepts the standard format \code{FORMAT\_MARMOTE} but also
the Maple format \code{FORMAT\_MAPLE}. In the first case, it writes:
"\code{Geometric on N with proba }$p$\code{: P(k) = }$(1-p)$\code{ x (}$p$\code{)\^{}k, k=0..+oo}". In the second case, it writes: "\code{Statistics[RandomVariable]( GeometricDistribution( }$1-p$\code{ ) )}".

\paragraph{Specific methods.} None.

%% The following methods are specific to the class:
%% \begin{quote}
%% \begin{verbatim}
%%   double 	p();
%%   double 	getRatio();
%%   double 	getProba(double k);
%% \end{verbatim}
%% \end{quote}
%% Both methods \code{p()} and \code{getRatio()} give access to the parameter $p$.
%% Methods \code{getProba()} returns the probability $P(X=k)$.

\subsubsection{\code{PoissonDistribution}}
\label{sec:PoissonDistribution}
\index{PoissonDistribution@\code{PoissonDistribution}!reference}

This is the Poisson distribution with some real parameter $\lambda$. It is given
by:
\begin{displaymath}
  P( X = k ) ~ = ~ \frac{\lambda^k}{k!} ~ e^{-\lambda}, \quad k\in\N.
\end{displaymath}

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmotePoissonDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class has a single constructor,

\begin{quote}
\begin{verbatim}
      PoissonDistribution( double lambda );
\end{verbatim}
\end{quote}
which sets the parameter $\lambda$. The value of $\lambda$ should be positive.
It can be equal to \code{INFINITE\_DURATION}.

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
  double   getProba( double k );
  double   Mean();
  double   Rate(); 
  double   Moment( int order );
  double   Variance();
  double   Laplace( double s );
  double   DLaplace( double s );
  double   Cdf( double x );
  double   Ccdf( double x );
  bool     HasMoment( int order );
  PoissonDistribution *Rescale( double factor );
  PoissonDistribution *Copy();
  double   Sample();
  void     IidSample( int n, double* s );
  void     Write( ostream* out, int mode );
\end{verbatim}
% std::string toString();
\end{quote}
These distributions have moments of any order, except when parameter $\lambda$ is
equal to 0. Rescaling a Poisson distribution by a factor $f$ returns
a Poisson distribution with parameter $\lambda\times f$.

%% Sampling from this distribution is possible only when \code{R} is enabled.
%% This feature is not available in the current version.
% See Section~\ref{sec:R}.
% \index{markovchain package (R)!sampling from Poisson distribution}

Method \code{Write()} accepts the standard format \code{FORMAT\_MARMOTE} but also
the Maple format \code{FORMAT\_MAPLE}. In the first case, it writes:
"\code{Poisson with rate }$\lambda$".
In the second case, it writes: "\code{Statistics[RandomVariable]( PoissonDistribution( }$\lambda$\code{ ) )}".

\paragraph{Specific methods.}

The following method is specific to the class:
\begin{quote}
\begin{verbatim}
  double 	lambda();
\end{verbatim}
\end{quote}
It is an accessor for parameter $\lambda$.

\subsubsection{\code{GammaDistribution}}
\label{sec:GammaDistribution}
\index{GammaDistribution@\code{GammaDistribution}!reference}

This is the Gamma distribution with shape parameter $k$ and
scale parameter $\theta$ (or rate parameter $\lambda=\theta^{-1}$).
It is given by its density:
\begin{displaymath}
  \mbox{d}P( X \leq x ) ~ = ~ \lambda ~ \frac{(\lambda x)^{k-1}}{\Gamma(k)}
  e^{-\lambda x} \mbox{d}x, \quad x \geq 0.
\end{displaymath}
The mean of the distribution is $k\theta$.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteGammaDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} This class has a single constructor

\begin{quote}
\begin{verbatim}
	GammaDistribution(double shape, double scale)
\end{verbatim}
\end{quote}
The shape parameter must be strictly positive. The scale parameter must
be positive. It can be equal to 0, in which case the distribution is
equivalent to a Dirac distribution at 0. The rate parameter is then
infinite. If illegal parameters are supplied to the constructor,
the default is returned, namely, the Exponential distribution with
parameter one, corresponding to $k = \lambda = \theta = 1.0$.

\paragraph{Re-implemented methods.} These methods are reimplemented
from \code{Distribution}.

\begin{quote}
\begin{verbatim}
  double	Mean();
  double	Rate(); 
  double	Moment( int order );
  double	Variance();
  double	Laplace( double s );
  double	DLaplace( double s );
  double	Cdf( double x );
  bool		HasMoment( int order );
  GammaDistribution *Rescale( double factor );
  GammaDistribution *Copy();
  double	Sample();
  void		Write( ostream* out, int mode );
  std::string   toString();
\end{verbatim}
\end{quote}
These distributions have moments of any order except when the scale
parameter is \code{INFINITE\_DURATION}.
Rescaling results in a new Gamma distribution.

The methods \code{Cdf()} and \code{Sample()} are currently not
implemented: the constant value \code{0.0} is returned, with a
warning.


Method \code{Write()}
reimplements the method from \code{Distribution}.
It accepts the standard format \code{FORMAT\_MARMOTE} but also
the Maple format \code{FORMAT\_MAPLE}. In the first case, it writes:
"\code{Gamma shape }$k$\code{ rate }$\lambda$".
In the second case, it writes: "\code{Statistics[RandomVariable]( GammaDistribution( }$\theta$\code{, }$k$\code{ ) )}".

\paragraph{Specific methods.} None.

%% \begin{quote}
%% \begin{verbatim}
%% \end{verbatim}
%% \end{quote}

\subsubsection{\code{ErlangDistribution}}
\label{sec:ErlangDistribution}
\index{ErlangDistribution@\code{ErlangDistribution}!reference}

This is the Erlang distribution with $k$ phases of mean $\theta$.  It
is actually the Gamma distribution with shape parameter $k$ and scale
parameter $\theta$ (or rate parameter $\lambda =
\theta^{-1}$. Accordingly, its density is
\begin{displaymath}
  \mbox{d}P( X \leq x ) ~ = ~ \lambda ~ \frac{(\lambda x)^{k-1}}{(k-1)!}
  e^{-\lambda x} \mbox{d}x, \quad x \geq 0,
\end{displaymath}
its cdf is:
\begin{displaymath}
  P( X \leq x ) ~ = ~ 1 - \sum_{j=0}^{k-1} \frac{(\lambda x)^{j}}{j!}
  e^{-\lambda x}, \quad x \geq 0,
\end{displaymath}
and its mean is $k\theta$. The class \code{ErlangDistribution} inherits
from \code{GammaDistribution}.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteErlangDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} This class has a single constructor

\begin{quote}
\begin{verbatim}
	ErlangDistribution(int phases, double scale)
\end{verbatim}
\end{quote}
The phases parameter is a strictly positive integer numbers. The scale
parameter must be positive. It can be equal to 0, in which case the
distribution is equivalent to a Dirac distribution at 0. The rate
parameter is then infinite. If illegal parameters are supplied to the
constructor, the default is returned, namely, the Exponential
distribution with parameter one, corresponding to $k = 1$, $\lambda =
\theta = 1.0$.

\paragraph{Re-implemented methods.} These methods are reimplemented
from \code{GammaDistribution}.

\begin{quote}
\begin{verbatim}
  double	Mean();
  double	Rate(); 
  double	Moment( int order );
  double	Variance();
  double	Laplace( double s );
  double	DLaplace( double s );
  double	Cdf( double x );
  ErlangDistribution *Rescale( double factor );
  ErlangDistribution *Copy( double factor );
  double	Sample();
  void		Write( ostream* out, int mode );
  std::string   toString();
\end{verbatim}
\end{quote}
Rescaling results in a new Erlang distribution.

Method \code{Write()}
reimplements the method from \code{GammaDistribution}.
It accepts the standard format \code{FORMAT\_MARMOTE} but also
the Maple format \code{FORMAT\_MAPLE}. In the first case, it writes:
"\code{Erlang phases }$k$\code{ rate }$\lambda$".
In the second case, it writes: "\code{Statistics[RandomVariable]( ErlangDistribution( }$\theta$\code{, }$k$\code{ ) )}".

\paragraph{Specific methods.} None.

%% \begin{quote}
%% \begin{verbatim}
%% \end{verbatim}
%% \end{quote}

\subsubsection{\code{ExponentialDistribution}}
\label{sec:ExponentialDistribution}
\index{ExponentialDistribution@\code{ExponentialDistribution}!reference}

This is the exponential distribution with parameter $\lambda$. It is given by:
\begin{displaymath}
  P( X \leq x ) ~ = ~ 1 - e^{-\lambda x}, \quad x \geq 0.
\end{displaymath}
This parameter $\lambda$ is the \emph{rate}. The \emph{mean} of the
distribution is $1/\lambda$.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteExponentialDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} This class has a single constructor

\begin{quote}
\begin{verbatim}
	ExponentialDistribution(double m)
\end{verbatim}
\end{quote}
The value \code{m} is the \emph{mean} of the random variable. It may be equal to
0, in which case the rate parameter $\lambda$ is infinite.
The mean should be positive. If an illegal parameter is provided, the
default Exponential(1.0) is returned.

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
  double	Mean();
  double	Rate(); 
  double	Moment( int order );
  double	Variance();
  double	Laplace( double s );
  double	DLaplace( double s );
  double	Cdf( double x );
  bool		HasMoment( int order );
  ExponentialDistribution *Rescale( double factor );
  ExponentialDistribution *Copy();
  double	Sample();
  void		Write( ostream* out, int mode );
  std::string   toString();
\end{verbatim}
\end{quote}
These distributions have moments of any order except when the
mean parameter $m$ is \code{INFINITE\_DURATION}.
Rescaling results in a new exponential distribution.

Method \code{Write()}
reimplements the method from \code{ErlangDistribution}.
It accepts the standard format \code{FORMAT\_MARMOTE} but also
the Maple format \code{FORMAT\_MAPLE}. In the first case, it writes:
"\code{Exponential distribution with mean }$1/\lambda$".
In the second case, it writes: "\code{Statistics[RandomVariable]( Exponential}
\code{Distribution( }$1/\lambda$\code{ ) )}".
The \code{toString()} method returns "\code{Exponential(m=}$1/\lambda$\code{)}".

\paragraph{Specific methods.} None.

%% \begin{quote}
%% \begin{verbatim}
%% \end{verbatim}
%% \end{quote}

\subsubsection{\code{UniformDistribution}}
\label{sec:UniformDistribution}
\index{UniformDistribution@\code{UniformDistribution}!reference}

This is the uniform distribution over some real interval $[a,b]$. It is given by
\begin{displaymath}
  P( X \leq x ) ~ = ~ \max\left\{ 0, \min\left\{ 1, \frac{x-a}{b-a} \right\} \right\}.
\end{displaymath}

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteUniformDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class has a single constructor:

\begin{quote}
\begin{verbatim}
UniformDistribution( double inf, double sup )
\end{verbatim}
\end{quote}
where \code{inf} and \code{sup} denote $a$ and $b$. The values should be such
that $a \leq b$ although this is not currently enforced.

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
  double	Mean();
  double	Rate(); 
  double	Moment( int order );
  double	Laplace( double s );
  double	DLaplace( double s );
  double	Cdf( double x );
  bool		HasMoment( int order );
  UniformDistribution *Rescale( double factor );
  UniformDistribution *Copy();
  double	Sample();
  double	IidSample();
  void		Write( ostream* out, int mode );
\end{verbatim}
\end{quote}
These distributions always have moments: \code{HasMoment()} always returns \code{true}.
Methods \code{Rescale()} and \code{Copy()} return \code{UniformDistribution} objects.

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
  double	valInf()
  double	valSup()
\end{verbatim}
\end{quote}
These are the accessors to the values of $a$ and $b$, respectively.

\subsubsection{\code{GaussianDistribution}}
\label{sec:GaussianDistribution}
\index{GaussianDistribution@\code{GaussianDistribution}!reference}

This is the scalar (univariate) Gaussian distribution. It is specified by
two parameters: its mean $m$ and variance $v$. The variance is the square of
the standard deviation $\sigma$.
The distribution is
given by its density:
\begin{displaymath}
  \frac{\mbox{d}P}{\mbox{d}x}( X \leq x ) ~ = ~ \frac{1}{\sqrt{2\pi v}} \; \exp\left(
  - \frac{(x-m)^2}{2v} \right).
\end{displaymath}

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmoteGaussianDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} This class has a single constructor:

\begin{quote}
\begin{verbatim}
GaussianDistribution( double mean, double variance )
\end{verbatim}
\end{quote}
which sets parameters $m$ and $v$.

\paragraph{Re-implemented methods.}
\begin{quote}
\begin{verbatim}
  double	Mean();
  double	Rate(); 
  double	Moment( int order );
  double	Laplace( double s );
  double	DLaplace( double s );
  double	Cdf( double x );
  double	Ccdf( double x );
  bool		HasMoment( int order );
  UniformDistribution *Rescale( double factor );
  UniformDistribution *Copy();
  double	Sample();
  void		Write( ostream* out, int mode );
\end{verbatim}
\end{quote}

These distributions have moments of any order: the method \code{HasMoment()} always
returns \code{true}. Rescaling by a factor $f$ produces a Gaussian distribution
with mean $f \times m$ and variance $f^2 \times v$.

Method \code{Write()}
reimplements the method from \code{Distribution}.
It accepts the standard format \code{FORMAT\_MARMOTE} but also
the Maple format \code{FORMAT\_MAPLE}. In the first case, it writes:
"\code{Gaussian mean }$m$\code{ variance }$v$".
In the second case, it writes: "\code{Statistics[RandomVariable]( GaussianDistribution( }$m$\code{, }$v^{1/2}$\code{ ) )}".

\paragraph{Specific methods.}

The following method is specific to the class:
\begin{quote}
\begin{verbatim}
double Variance()
\end{verbatim}
\end{quote}
It gives access to parameter $v$.

\subsubsection{\code{PhaseTypeDistribution}}
\label{sec:PhaseTypeDistribution}
\index{PhaseTypeDistribution@\code{PhaseTypeDistribution}!reference}

This class represents the phase-type distribution with a discrete (and
finite) phase space.  It is characterized by a continuous-time
transition structure $T$ and an initial distribution $\beta$ on the
phase space. The transition structure is a priori ''sub-stochastic''
so that jumps are possible to some state outside the phase state,
called the terminal state.  The distribution is that of the time it
takes for the continuous-time Markov chain with generator $T$ to hit
the terminal state (i.e. exit the phase space), when it starts from
distribution $\beta$.  It may be that the distribution is defective:
when the terminal state is never reached with some positive
probability.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmotePhaseTypeDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class has a single constructor:

\begin{quote}
\begin{verbatim}
PhaseTypeDistribution(TransitionStructure* T, DiscreteDistribution* beta );
\end{verbatim}
\end{quote}
It defines the values of $T$ and $\beta$.

\paragraph{Re-implemented methods.}
The following methods are re-implemented from \code{Distribution}:

\begin{quote}
\begin{verbatim}
double  Mean();
double  Rate(); 
double  Moment( int order );
double  Variance();
double  Laplace( double s );
double  DLaplace( double s );
double  Cdf( double x );
double  Ccdf( double x );
bool    HasMoment( int order );
UniformDiscreteDistribution *Rescale( double factor );
UniformDiscreteDistribution *Copy();
double	Sample();
void    IidSample( int n, double* s );
void    Write( ostream* out, int mode );
\end{verbatim}
%  std::string toString();
\end{quote}
The mean is given by the formula $m = \beta T^{-1} \mathbf{1}$. In the defective
case, this evaluates to \code{INFINITE\_DURATION}.
\index{infinity (numerical representation)!\code{INFINITE\_DURATION}!in phase-type distributions}
The \code{Moment()} method is restricted to order 2; the second moment is
$m_2 = 2\beta T^{-2} \mathbf{1}$. The distribution has moments of all orders if
$m < \infty$, so that the argument of \code{HasMoment()} is ignored.
The computation of cdf and its Laplace transform, \code{Cdf()}, \code{Ccdf()},
\code{Laplace()} and \code{DLaplace()}, is currently not implemented.
Rescaling by a factor $f$ produces a phase-type distribution with same
distribution $\beta$ and phase transitions $fT$.

Sampling of the distribution with \code{Sample()} and
\code{IidSample()} by simulating hitting times of the associated
Markov chain (see Section~\ref{sec:hitting-times}).
\index{hitting times!for phase-type distributions}

The \code{Write()} method accepts only the standard format \code{FORMAT\_MARMOTE}
and produces as output:
\begin{quote}
\begin{verbatim}
Continuous-time Phase-type with rate matrix: [ ... ] and proba vector ...
\end{verbatim}
\end{quote}

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
TransitionStructure* trans() { return trans_; }
DiscreteDistribution* iDis() { return iDis_; }
\end{verbatim}
\end{quote}
They are the accessors to the parameters $T$ and $\beta$ of the distribution.

\subsubsection{\code{PhaseTypeDiscreteDistribution}}
\label{sec:PhaseTypeDiscreteDistribution}
\index{PhaseTypeDiscreteDistribution@\code{PhaseTypeDiscreteDistribution}!reference}

This class represents the discrete-time phase-type distribution with a discrete (and
finite) phase space.  It is characterized by a probability transition
structure $P$ and an initial distribution $\beta$ on the
phase space. The transition structure is a priori sub-stochastic
so that jumps are possible to some state outside the phase state,
called the terminal state.  The distribution is that of the time (number of steps) it
takes for the continuous-time Markov chain with generator $T$ to hit
the terminal state (i.e. exit the phase space), when it starts from
distribution $\beta$.  It may be that the distribution is defective:
when the terminal state is never reached with some positive
probability.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmotePhaseTypeDiscreteDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} The class has a single constructor:

\begin{quote}
\begin{verbatim}
PhaseTypeDiscreteDistribution(TransitionStructure* T, DiscreteDistribution* beta );
\end{verbatim}
\end{quote}

\paragraph{Re-implemented methods.}
The following methods are re-implemented from \code{Distribution}:

\begin{quote}
\begin{verbatim}
double  Mean();
double  Rate(); 
double  Moment( int order );
double  Variance();
double  Laplace( double s );
double  DLaplace( double s );
double  getProba(double value);
double  getProbaByIndex(double value);
double  Cdf( double x );
double  Ccdf( double x );
bool    HasMoment( int order );
UniformDiscreteDistribution *Rescale( double factor );
UniformDiscreteDistribution *Copy();
double	Sample();
void    IidSample( int n, double* s );
void    Write( ostream* out, int mode );
\end{verbatim}
\end{quote}

The mean is given by the formula $m = \beta (I-P)^{-1} \mathbf{1}$. In the defective
case, this evaluates to \code{INFINITE\_DURATION}.
\index{infinity (numerical representation)!\code{INFINITE\_DURATION}!in phase-type distributions}
The \code{Moment()} method is currently restricted to order 1.
% 2; the second moment is $m_2 = 2\beta (I-P)^{-2} \mathbf{1}$.
The distribution has moments of all orders if
$m < \infty$, so that the argument of \code{HasMoment()} is ignored.
The computation of the Laplace transform, \code{Laplace()} and \code{DLaplace()},
is currently not implemented.
Rescaling is not possible for these distributions: a copy is returned by
\code{Rescale()} with a warning message.

Sampling of the distribution with \code{Sample()} and
\code{IidSample()} by simulating hitting times of the associated
Markov chain (see Section~\ref{sec:hitting-times}).
\index{hitting times!for phase-type distributions}

The \code{Write()} method accepts only the standard format \code{FORMAT\_MARMOTE}
and produces as output:
\begin{quote}
\begin{verbatim}
Discrete-time Phase-type with rate matrix: [ ... ] and proba vector ...
\end{verbatim}
\end{quote}

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
TransitionStructure* trans() { return trans_; }
DiscreteDistribution* iDis() { return iDis_; }
\end{verbatim}
\end{quote}
They are the accessors to the parameters $P$ and $\beta$ of the distribution.

\begin{comment}
\subsubsection{\code{TemplateDistribution}}

This is the template for the description of a distribution.

Description TBD.

\paragraph{Definition.} This class is accessed with the directive
\begin{quote}
\begin{verbatim}
#include "marmoteCore/marmote_templateDistribution.h"
\end{verbatim}
\end{quote}

\paragraph{Constructors.} This class has ... constructors.

\begin{quote}
\begin{verbatim}
\end{verbatim}
\end{quote}

\paragraph{Re-implemented methods.}

\begin{quote}
\begin{verbatim}
\end{verbatim}
\end{quote}

\paragraph{Specific methods.}

The following methods are specific to the class:
\begin{quote}
\begin{verbatim}
\end{verbatim}
\end{quote}
\end{comment}


\newpage

\tableofcontents

\appendix

\chapter{Examples}

The examples of use of \code{marmoteCore} are organized in two
sets: Basic and Advanced.

\section{Basic examples}

The basic examples show how to construct simple Markov chains and
call basic solution functions. We briefly comment below the principal
functionalities and programming specificities.
%% These examples also illustrate memory management.

\subsection{Example 1}

This example creates a 3-state, discrete-time Markov chain, then performs
a (Monte-Carlo) simulation of it. The matrix is:
\begin{displaymath}
  P =
  \begin{pmatrix} 0.25 & 0.5 & 0.25 \\ 0.4 & 0.2 & 0.4 \\ 0.4 & 0.3 & 0.3
  \end{pmatrix}
  .
\end{displaymath}
Usage:
\begin{verbatim}
    example1 <n> <p1> <p2> <p3>
\end{verbatim}
Here, \code{n} is the number of steps for the simulation, and \code{p1}, \code{p2},
\code{p3} are the respective initial probabilities of the three states.

Tasks performed:
\begin{itemize*}
\item create a \code{DiscreteDistribution} object to hold the initial
  distribution of the process
\item create a \code{SparseMatrix} object to hold the transition matrix
  of the chain, entry by entry with the \code{addToEntry()} function;
\item create a \code{MarkovChain} object and link the previous elements to it;
\item output the Markov chain object to the screen;
\item create a simulation of a trajectory and store it in a
  \code{SimulationResult} object;
\item write the trajectory to the screen;
\item clean up.
\end{itemize*}

\subsection{Example 2}

This example creates the same 3-state discrete-time Markov chain as in Example 1,
then computes the transient distribution of the chain after a given number of
steps. Usage:
\begin{verbatim}
    example2 <n> <p1> <p2> <p3>
\end{verbatim}
Here, \code{n} is the number of steps for the transient distribution,
and \code{p1}, \code{p2},
\code{p3} are the respective initial probabilities of the three states.

Tasks performed:
\begin{itemize*}
\item create a \code{DiscreteDistribution} object to hold the initial
  distribution of the process
\item create a \code{SparseMatrix} object to hold the transition matrix
  of the chain, entry by entry with the \code{addToEntry()} function;
\item create a \code{MarkovChain} object and link the previous elements to it;
\item output the Markov chain object to the screen;
\item calculate the transient distributions after \code{n} steps and store it in a
  \code{Distribution} object;
\item write the distribution to the screen;
\item clean up.
\end{itemize*}

\subsection{Example 3}

This example creates three slightly different 8-state, discrete-time Markov chains,
then computes the transient distribution of the chain after a given number of
steps. The matrices are:
\begin{displaymath}
  \small
  P_1 =
  \begin{pmatrix}
    0.2 & 0.8 & & & & & & \\
    0.25 & 0.25 & 0.25 & 0.25 & & & & \\
    0.6 & & 0.4 & & & & & \\
    & & 0.3 & 0.2 & 0.25 & 0.25 & & \\
    & & & & 0.1 & 0.3 & 0.3 & 0.3 \\
    & & & & & 1.0 & & \\
    & & & & 0.5 & & 0.5 & \\
    & & & & 0.4 & 0.2 & 0.2 & 0.5 
  \end{pmatrix}
  ~~
  P_2 =
  \begin{pmatrix}
    0.2 & 0.8 & & & & & & \\
    0.25 & 0.25 & 0.25 & 0.25 & & & & \\
    0.6 & & 0.4 & & & & & \\
    & & 0.3 & 0.2 & 0.25 & 0.25 & & \\
    & & & & 0.1 & 0.3 & 0.3 & 0.3 \\
    & & & & & 0.5 & & 0.5 \\
    & & & & 0.5 & & 0.5 & \\
    & & & & 0.4 & 0.2 & 0.2 & 0.5 
  \end{pmatrix}
\end{displaymath}
\begin{displaymath}
  \small
  P_3 =
  \begin{pmatrix}
    0.2 & 0.8 & & & & & & \\
    0.25 & 0.25 & 0.25 & 0.25 & & & & \\
    0.6 & & 0.4 & & & & & \\
    & & 0.3 & 0.2 & 0.25 & 0.25 & & \\
    & & & & 0.1 & 0.3 & 0.3 & 0.3 \\
    & & & 0.5 & & 0.5 & & \\
    & & & & 0.5 & & 0.5 & \\
    & & & & 0.4 & 0.2 & 0.2 & 0.5 
  \end{pmatrix}
\end{displaymath}
Usage:
\begin{verbatim}
    example3 <n> <p1> <p2> <p3> <p4> <p5> <p6> <p7> <p8>
\end{verbatim}
Here, \code{n} is the number of steps for the simulation, and \code{p1}, \code{p2},
etc. are the respective initial probabilities of the eight states.

Tasks performed:
\begin{itemize*}
\item create a \code{DiscreteDistribution} object to hold the initial
  distribution of the process
\item create three \code{SparseMatrix} objects to hold the transition matrix
  of the chain, entry by entry with the \code{addToEntry()} function;
\item create three \code{MarkovChain} objects and link the previous elements to it;
\item calculate the transient distributions after \code{n} steps for each
  Markov chain and store it in a \code{Distribution} object;
\item write the distributions to the screen;
\item clean up.
\end{itemize*}

\subsection{Example 4}

This example creates two Markov chains by reading them from files, then outputs them
to other files: either as whole Markov chains, either only their generators.
The matrices are:
\begin{displaymath}
  P_1
  =
  \begin{pmatrix}
    0.2 & 0.8 & & & & & & \\
    0.25 & 0.25 & 0.25 & 0.25 & & & & \\
    0.6 & & 0.4 & & & & & \\
    & & 0.3 & 0.2 & 0.25 & 0.25 & & \\
    & & & & 0.1 & 0.3 & 0.3 & 0.3 \\
    & & & & & 1 & & \\
    & & & & 0.5 & & 0.5 & \\
    & & & & 0.4 & 0.2 & 0.2 & 0.2
  \end{pmatrix}
  \quad
  P_2
  =
  \begin{pmatrix}
    0.6 & 0.4 & & & & & & \\
    0.3 & 0.3 & 0.4 & & & & & \\
    & 0.3 & 0.3 & 0.4 & & & & \\
    & & 0.3 & 0.3 & 0.4 & & & \\
    & & & 0.3 & 0.3 & 0.4 & & \\
    & & & & 0.3 & 0.3 & 0.4 & \\
    & & & & & 0.3 & 0.3 & 0.4 \\
    & & & & & & 0.3 & 0.7
  \end{pmatrix}
\end{displaymath}
Usage:
\begin{verbatim}
    example4
\end{verbatim}

Tasks performed:
\begin{itemize*}
\item create two \code{MarkovChain} objects by reading their description in
  files \code{IO\_example\_in1.mcl} and \code{IO\_example\_in2.mcl};
\item output them again to files \code{IO\_example\_out1.mcl}
  and \code{IO\_example\_out2.mcl};
\item write the generator of these chains to files
  \code{IO\_example\_mat1.mmt} and \code{IO\_example\_mat2.mmt};
\item clean up.
\end{itemize*}

A specificity is the test that the generator is present (not \code{NULL}) before
attempting to write it to the file. Indeed, if the file is not found, or not
in the proper format, the chain is created but with an empty generator
(see Section~\ref{sec:MarkovChain-I/O}).

\subsection{Example 5}

This example creates the same 3x3 Markov Chain as in Example 1, then tries two different
methods for computing the stationary distribution. The invariance of this
distribution is tested. It is also compared with a transient distribution.
Usage:
\begin{verbatim}
    example5
\end{verbatim}

Tasks performed:
\begin{itemize*}
\item create a random \code{DiscreteDistribution} object to hold the initial
  distribution of the process
\item create a \code{SparseMatrix} object to hold the transition matrix
  of the chain, entry by entry with the \code{addToEntry()} function;
\item create a \code{MarkovChain} object and link the previous elements to it;
\item compute the stationary distribution using methods
  \code{StationaryDistribution()} and \code{StationaryDistributionPower()}
  (see Section~\ref{sec:MarkovChain-stationary});
\item compute the one-step transient distribution $\pi_1$, starting
  from one of these stationary distributions $\pi_\infty$ taken as
  initial distribution $\pi_0$, and calculate
  the L1 distance $||\pi_0 - \pi_1||_1$;
\item compute the 100-step transient distribution $\pi_{100}$, starting
  from the random initial distribution, and calculate
  the L1 distance $||\pi_\infty - \pi_{100}||_1$;
\item clean up.
\end{itemize*}

This example features the use of a \code{UniformDistribution} object to
generate random values.

\subsection{Example 6}

This example handles \code{Set} objects, more precisely
one \code{MarmoteInterval} object, and
\code{MarmoteBox} objects of several dimensions. Usage:
\begin{verbatim}
    example6
\end{verbatim}
Tasks performed:
\begin{itemize*}
\item create two \code{MarmoteBox} objects with one and two dimensions and one
  \code{MarmoteInterval} object
\item enumerate them with different methods:
  \begin{itemize}
    \item use the member function \code{Enumerate()}
    \item use the walkthrough facilities \code{FirstState()/NextState()/IsFirst()}
    \item use the \code{Cardinal()/DecodeState()} facilities
  \end{itemize}
\item redo the test with upcast pointers of type MarmoteSet
\item clean up.
\end{itemize*}

\subsection{Example 7}

This example demonstrates the structural analysis possibilities for
\code{MarkovChain} objects. Usage:
\begin{verbatim}
    example7
\end{verbatim}
Tasks performed:
\begin{itemize*}
\item create four discrete-time \code{SparseMatrix} objects
\item create four \code{MarkovChain} objects and set their generators to the
  previously created \code{SparseMatrix} objects
\item perform a structural analysis of the (graph of the) \code{MarkovChain}s:
  \begin{itemize}
  \item run the \code{Diagnose()} utility on the generator
  \item find absorbing states with \code{AbsorbingStates()} and list them
  \item find communicating classes with \code{CommunicatingClasses()} and list them
  \item find recurrent classes with \code{RecurrentClasses()} and list them
  \item compute the period with \code{Period()} and print it
  \end{itemize}
\item clean up.
\end{itemize*}

The four transition structures analyzed are displayed in Figure~\ref{fig:example7}. The three first of them are matrices $P_1$, $P_2$ and $P_3$ of Example 3.
The probabilities of transitions are not represented since they are not relevant to
this analysis.
\begin{figure}
  \begin{center}
    \includegraphics[width=\textwidth]{Figures/example7}
    \caption{Diagrams of the four Markov chains analyzed in Example 7}
    \label{fig:example7}
  \end{center}
\end{figure}

\section{Advanced examples}

\subsection{Using complex \code{MarmoteSet} objects}

TBD

\subsection{Using the hierarchy of models}

TBD

\chapter{The Markov Zoo}
\label{chap:zoo}

A hierarchy of continuous-time models is proposed in the diagram below.
Models featured in grey are those currently impemented.
Abbreviations used are:
ASEP for Asymmetric Exclusion Process,
MAP for Markov Arrival Process (and not Markov \textit{Additive} Process),
BMAP for Batch Markov Arrival Process,
IPP for Interrupted Poisson Process,
MMPP for Markov-Modulated Poisson Process,
QBD for Quasi-Birth-Death.
Other names are classical in thir respective fields.

\section{The Continuous-Time Markov Zoo}
\label{sec:zoo-CT}

  \begin{center}
    \includegraphics[width=\textwidth]{Figures/MarkovZoo_CT.pdf}
  \end{center}

\section{The Discrete-Time Markov Zoo}
\label{sec:zoo-DT}

A hierarchy of discrete-time models is proposed in the diagram below.
Models featured in grey are those currently impemented.
Abbreviations used are:
GW for Galton-Watson,
QBD for Quasi-Birth-Death,
FC96 for Felsenstein-Churchill 96,
CPED for Constant-Probability Event-Driven process.
Other names are classical in thir respective fields.

  \begin{center}
    \includegraphics[width=\textwidth]{Figures/MarkovZoo_DT.pdf}
  \end{center}


\chapter{File formats}
\label{chap:formats}

\section{Xborne}
\label{sec:Xborne-format}
\index{Xborne!format specification}

The Xborne suite uses a multi-file format for representing matrices
and the state spaces on which they are defined.

\paragraph{Size.} A file with extension \code{.sz} normally contains
three integer numbers on three lines. The first line is the number of
non-zero entries, then the number of states reachable from the initial
state, then the dimension of the state space, considered as a
subset of $\N^d$.

\paragraph{State space.} Xborne represents state spaces as a subset
of $\N^d$. The value of $d$ is in the ``\code{.sz} file.
The files with extensions \code{.cd} do the mapping between
this multidimensional representation and the numbering of states.
States are numbered starting with 0.
Each row of the file begins with the index number of some state,
and continues with the list of $d$ coordinates, separated with
white spaces or tabulations.
States need not be present in increasing index order in the file.

The following example \code{testB3.cd} from the distribution of Xborne,
represents the state $\{0,1,2\}^3$ with 27 elements.
\begin{verbatim}
           0           0           0           0
           1           1           0           0
           2           2           0           0
           3           0           1           0
           4           1           1           0
           5           2           1           0
           6           0           2           0
...
          21           0           1           2
          22           1           1           2
          23           2           1           2
          24           0           2           2
          25           1           2           2
          26           2           2           2
\end{verbatim}

\paragraph{Matrices.} Matrices of Xborne are stored in different formats.
\code{marmoteCore} uses primarily the ``increasing row/increasing column''
format, abbreviated as ``Rii''.

In the Rii format, each line starts with the origin state index. It is
followed by the number of entries in that row of the matrix. Then the
entries themselves follow as pairs probability/destination state.
All fields are separated by white spaces.

The following is the complete specification of the homogeneous 1-d
random walk with 10 states and left/right probabilities 0.3 and 0.4.

\begin{center}
  \small
\begin{verbatim}
      0          2 6.000000e-01          0 4.000000e-01          1
      1          3 3.000000e-01          0 3.000000e-01          1 4.000000e-01          2
      2          3 3.000000e-01          1 3.000000e-01          2 4.000000e-01          3
      3          3 3.000000e-01          2 3.000000e-01          3 4.000000e-01          4
      4          3 3.000000e-01          3 3.000000e-01          4 4.000000e-01          5
      5          3 3.000000e-01          4 3.000000e-01          5 4.000000e-01          6
      6          3 3.000000e-01          5 3.000000e-01          6 4.000000e-01          7
      7          3 3.000000e-01          6 3.000000e-01          7 4.000000e-01          8
      8          3 3.000000e-01          7 3.000000e-01          8 4.000000e-01          9
      9          2 3.000000e-01          8 7.000000e-01          9
\end{verbatim}
\end{center}

% \section{HBF}

\section{MARCA}
\label{sec:MARCA}
\index{MARCA!format specification}

The MARCA format is defined in William Stewart's MARCA suite.
It is one of the formats supported by the PSI1 suite of programs.

The first line comprises three integer numbers, respectively
the row dimension, the column dimension and the number of non-zero
entries of the matrix.

The second line is empty. The following ones list the entries as
triples $(i,j,T_{i,j})$. States are numbered starting from 1.

The following example is the complete specification of a homogeneous 1-d
random walk with 5 states and left/right probabilities 0.3 and 0.4.
\begin{verbatim}
    5     5     13

         1          1 6.000000e-01
         1          2 4.000000e-01
         2          1 3.000000e-01
         2          2 3.000000e-01
         2          3 4.000000e-01
         3          2 3.000000e-01
         3          3 3.000000e-01
         3          4 4.000000e-01
         4          3 3.000000e-01
         4          4 3.000000e-01
         4          5 4.000000e-01
         5          4 3.000000e-01
         5          5 7.000000e-01
\end{verbatim}
        
\section{Ers}
\label{sec:Ers-specification}

A simple text format where transitions are listed as triples
$(i,j,T_{i,j})$. The first line indicates whether the model is
discrete or continuous. The keyword \code{sparse} is implicit.
The second line describes the size of the state space.
The following ones are the entries. The lists ends with the keyword \code{stop}.
A last line specifies the initial state.

States are numbered starting with 0.

The following example specifies a discrete-time Markov chain with 16 states
and 0 initial state.
\begin{verbatim}
discrete sparse
16
0 0 0.9091
0 4 0.0909
1 1 0.9091
...
stop
0
\end{verbatim}

The following example specifies a continuous-time Markov chain with 101 states
and 100 as initial state. Observe that diagonal entries are \emph{not} listed:
they are deduced from the off-diagonal entries.
\begin{verbatim}
continuous sparse
101
0 1 1.000000
1 0 1.000000
1 2 0.500000
2 1 1.000000
2 3 0.333333
3 2 1.000000
3 4 0.250000
...
99 98 1.000000
100 99 1.000000
stop
100
\end{verbatim}

\section{R}
\label{sec:R-format}
\index{R!Markov chain format}

The \code{R} output format is compatible with the \code{markovchain} package.
It is a full matrix format. The Markov chain is written as:
\begin{itemize}
\item a matrix, in the form: \code{generator<-matrix(c(<entry>,<entry>,...),nrow=<size>,byrow=TRUE)}
\item a state space, in the form: \code{statenames<-c("<name>","<name>",...)}
\item the chain itself, in the form: \code{mc<-new("markovchain",states=statenames,transitionmatrix=generator)}
\end{itemize}

\section{Scilab}
\label{sec:Scilab-format}

The \code{Scilab} output format is available only for transition structures.
The matrix is written as:
\begin{verbatim}
      gen = [<entry> <entry> <entry> ....; <entry> <entry> <entry> ....; ...];
\end{verbatim}

\section{Maple}
\label{sec:Matlab-format}

The \code{Maple} output format is available only for transition structures.
It uses the sparse matrix format of Maple: entries are listed as
a list of \code{(i,j)=value}. The user is responsible for wrapping this
list into the \text{linalg/matrix} or \text{LinearAlgebra/Matrix} formats.

\section{Matrix Market}
\label{sec:MatrixMarket-format}
\index{Matrix Market!format specification}

The \code{MatrixMarket} output format is available only for transition structures.
This format has been specified by NIST, see:
\url{https://math.nist.gov/MatrixMarket/formats.html}.
There are two variants: the ``coordinate'' format for sparse matrices,
and the ``array'' format for full matrices.
In general, a line beginning with ``\code{\%}'' is a comment.

\begin{itemize}
\item Sparse matrices: the file begins with the header \hfill\break
  \centerline{\code{\%\%MatrixMarket matrix coordinate real general}}.
  The first (non-comment) line contains three numbers: row size, column size and number of
  non-zero entries. The entries then follow in the format \code{row col value}.
  
  This format is similar to the \code{MARCA} format (Appendix~\ref{sec:MARCA})
  except that the blank line after the size specification is not mandatory.
  On the other hand, the format is ``flexible'' in the sense that extra blank
  lines may be inserted. 
  
\item Full matrices: the file begins with the header \\
  \centerline{\code{\%\%MatrixMarket matrix array real general}}.
  The first (non-comment) line contains two numbers: row size and column size.
  The entries then follow, one by row.
  
\end{itemize}

\section{Harwell-Boeing (HB)}
\label{sec:HarwellBoeing-format}
\index{Harwell-Boeing!format specification}

The Harwell-Boeing format (HB or HBF) is a compact coding of matrices.
Its implementation in \code{marmote} is pending.

\printindex

\end{document}

%%% Atelier

Atelier Logiciel Marmote du 15 Septembre 2015
tapes Prparatoires

Atelier Marmote-Utilisateur

%%% Todo


R install packages
also serves for updating packages

Scilab
atomsInstall(``metanet'')


memo analyse spectrale a partir de scilab ou R
