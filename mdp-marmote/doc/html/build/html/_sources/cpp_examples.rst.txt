C++ Tutorial and Examples
-------------------------

.. toctree::
   :maxdepth: 2
   :caption: Table of Examples
   :name: cppexampletoc
   :hidden:

   example/example1
   example/example2
   example/example3
   example/example4
   example/example5
   example/example6
   example/example7
   example/example10
   example/exampleMDP10
   example/exampleMDP11
   example/exampleMDP21
   example/exampleMDP31
   example/exampleMDP40

The following examples show elementary manipulations of Marmote objects:

* :doc:`Example 1 <./example/example1>`: create a Markov Chain and perform Monte-Carlo simulation
* :doc:`Example 2 <./example/example2>`: create a Markov Chain and compute transient distributions
* :doc:`Example 3 <./example/example3>`: as in Example 2 with several chains
* :doc:`Example 4 <./example/example4>`: read and write Markov Chains from/to files
* :doc:`Example 5 <./example/example5>`: create a Markov Chain and compute the stationary distribution with different methods
* :doc:`Example 6 <./example/example6>`: manipulate Sets (state spaces)
* :doc:`Example 7 <./example/example7>`: create Markov Chains and perform structural analysis

The following examples show how to use more advanced Marmote objects:

* :doc:`Example 10 <./example/example10>`: use the multidimensional random walk objects

The following examples to manipulate Markov Decision Process are provided:

* :doc:`ExampleMDP 10: <./example/exampleMDP10>` create a discounted MDP object and describes the generalities about the MDP modelling. It also contains a short presentation of the MDP solver.
* :doc:`ExampleMDP 11: <./example/exampleMDP11>` create a discounted MDP and illustrate the way to get the same action set for any state. 
* :doc:`ExampleMDP 21: <./example/exampleMDP21>` create an average MDP and illustrate the way to evaluate a policy.
* :doc:`ExampleMDP 31: <./example/exampleMDP31>` create an total Cost MDP for computing the well known SSP *four room* and illustrate how to manipulate a **multidimensionnal state space**.
* :doc:`ExampleMDP 40: <./example/exampleMDP40>` create a finite horizon MDP given by Puterman in his book.
