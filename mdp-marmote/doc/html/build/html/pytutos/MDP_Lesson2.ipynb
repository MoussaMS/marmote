{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDP Lesson 2: additional methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:06.571123Z",
     "iopub.status.busy": "2025-06-10T21:16:06.570915Z",
     "iopub.status.idle": "2025-06-10T21:16:06.758711Z",
     "shell.execute_reply": "2025-06-10T21:16:06.757909Z"
    }
   },
   "outputs": [],
   "source": [
    "import marmote.core as mc\n",
    "import marmote.markovchain as mmc\n",
    "import marmote.mdp as md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:06.761617Z",
     "iopub.status.busy": "2025-06-10T21:16:06.760869Z",
     "iopub.status.idle": "2025-06-10T21:16:06.765292Z",
     "shell.execute_reply": "2025-06-10T21:16:06.764532Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Model](#model)\n",
    "2. [Build the MDP - Constructor 1](#build-the-mdp---constructor-1)\n",
    "3. [Build the MDP - Constructor 2](#build-the-mdp---constructor-2)\n",
    "4. [Build the MDP - Constructor 3](#build-the-mdp---constructor-3)\n",
    "5. [Q-Value](#q-value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "[Back to Table of Contents](#table-of-contents)\n",
    "\n",
    "### Description of the Model\n",
    "We use a model with three states *s1, s2, s3* and three actions *a0, a1, a2*. Transition probabilities and rewards are described by the picture below.\n",
    "\n",
    "<img src=\"./geron.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the MDP - Constructor 1\n",
    "\n",
    "[Back to Table of Contents](#table-of-contents)\n",
    "\n",
    "### Creating States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:06.767503Z",
     "iopub.status.busy": "2025-06-10T21:16:06.767320Z",
     "iopub.status.idle": "2025-06-10T21:16:06.771394Z",
     "shell.execute_reply": "2025-06-10T21:16:06.770626Z"
    }
   },
   "outputs": [],
   "source": [
    "actionSpace = mc.MarmoteInterval(0, 2)\n",
    "stateSpace = mc.MarmoteInterval(0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some modelling choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it could be noticed, the number of actions is not the same in each state. In state *s1* one could trigger any of the actions *a0*, *a1*, and *a2* while in state *s3* only action *a2* can be triggered. \n",
    "\n",
    "To make programming easier, we have chosen to have an identical action space in each state. This means that we can activate all actions *a0*, *a1*, *a2* in all state. To do this, we add missing actions which will have no effect and which will receive a high cost. \n",
    "\n",
    "Hence in state *s3* we add action *a0* with a transition to *s3* with probability *1*. \n",
    "\n",
    "Hence in state *s3* we add action *a0* with a transition to *s3* with probability *1*. \n",
    "\n",
    "Hence in state *s2* we add action *a2* with a transition to *s2* with probability *1*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we enter the transition matrices (we do not entry the null values) and add each matrix to a list. The matrices obey to the modeling choice presented above and then have the same dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the MDP - Constructor 2\n",
    "\n",
    "[Back to Table of Contents](#table-of-contents)\n",
    "\n",
    "### Creating Transitions Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:06.773530Z",
     "iopub.status.busy": "2025-06-10T21:16:06.773360Z",
     "iopub.status.idle": "2025-06-10T21:16:06.778446Z",
     "shell.execute_reply": "2025-06-10T21:16:06.777757Z"
    }
   },
   "outputs": [],
   "source": [
    "trans = list()\n",
    "\n",
    "# matrix for the a_0 action\n",
    "P0 = mc.SparseMatrix(3)\n",
    "P0.setEntry(0, 0, 0.7)\n",
    "P0.setEntry(0, 1, 0.3)\n",
    "P0.setEntry(1, 1, 1.0)\n",
    "P0.setEntry(2, 2, 1.0)\n",
    "trans.append(P0)\n",
    "\n",
    "# matrix for the a_1 action\n",
    "P1 = mc.SparseMatrix(3)\n",
    "P1.setEntry(0, 0, 1.0)\n",
    "P1.setEntry(1, 2, 1.0)\n",
    "P1.setEntry(2, 2, 1.0)\n",
    "trans.append(P1)\n",
    "\n",
    "# matrix for the a_2 action\n",
    "P2 = mc.SparseMatrix(3)\n",
    "P2.setEntry(0, 0, 0.8)\n",
    "P2.setEntry(0, 1, 0.2)\n",
    "P2.setEntry(1, 1, 1.0)\n",
    "P2.setEntry(2, 0, 0.8)\n",
    "P2.setEntry(2, 1, 0.1)\n",
    "P2.setEntry(2, 2, 0.1)\n",
    "trans.append(P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the MDP - Constructor 3\n",
    "\n",
    "[Back to Table of Contents](#table-of-contents)\n",
    "\n",
    "### Creation of several rewards matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the reward values depend on the transition with a cost per transition, then we use a second way to build the MDP. \n",
    "We use a second constructor which uses two lists of matrices. One for the transition matrices as before and another for the rewards per transition. For the later list, the matrix at the *k*-th entry defines the gains associated with the action with index *k*. In this matrix, the entry with coordinate (i,j) defines the reward of the transition from i to j.\n",
    "\n",
    "We also define the penalty given to unavailable actions. Here a small negative value (-10^5) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:06.780416Z",
     "iopub.status.busy": "2025-06-10T21:16:06.780247Z",
     "iopub.status.idle": "2025-06-10T21:16:06.785047Z",
     "shell.execute_reply": "2025-06-10T21:16:06.784253Z"
    }
   },
   "outputs": [],
   "source": [
    "penalty = -100000\n",
    "\n",
    "R1 = mc.SparseMatrix(3)\n",
    "R2 = mc.SparseMatrix(3)\n",
    "R3 = mc.SparseMatrix(3)\n",
    "\n",
    "# fill in non null entries in sparse matrix\n",
    "R1.setEntry(0, 0, 10)\n",
    "R1.setEntry(2, 2, penalty)\n",
    "\n",
    "R2.setEntry(1, 2, -50)\n",
    "R2.setEntry(2, 2, penalty)\n",
    "\n",
    "R3.setEntry(1, 1, penalty)\n",
    "R3.setEntry(2, 0, 40)\n",
    "\n",
    "# Adding reward to list\n",
    "rews = list()\n",
    "rews.append(R1)\n",
    "rews.append(R2)\n",
    "rews.append(R3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:06.786884Z",
     "iopub.status.busy": "2025-06-10T21:16:06.786719Z",
     "iopub.status.idle": "2025-06-10T21:16:06.790758Z",
     "shell.execute_reply": "2025-06-10T21:16:06.790122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking\n",
      "R1 [[1.000000e+01, 0.000000e+00, 0.000000e+00],\n",
      " [0.000000e+00, 0.000000e+00, 0.000000e+00],\n",
      " [0.000000e+00, 0.000000e+00, -1.000000e+05]]\n",
      "\n",
      "R2 [[0.000000e+00, 0.000000e+00, 0.000000e+00],\n",
      " [0.000000e+00, 0.000000e+00, -5.000000e+01],\n",
      " [0.000000e+00, 0.000000e+00, -1.000000e+05]]\n",
      "\n",
      "R3 [[0.000000e+00, 0.000000e+00, 0.000000e+00],\n",
      " [0.000000e+00, -1.000000e+05, 0.000000e+00],\n",
      " [4.000000e+01, 0.000000e+00, 0.000000e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking\")\n",
    "print(\"R1\", str(R1))\n",
    "print(\"R2\", str(R2))\n",
    "print(\"R3\", str(R3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:06.822516Z",
     "iopub.status.busy": "2025-06-10T21:16:06.822197Z",
     "iopub.status.idle": "2025-06-10T21:16:06.826698Z",
     "shell.execute_reply": "2025-06-10T21:16:06.825914Z"
    }
   },
   "outputs": [],
   "source": [
    "beta = 0.95\n",
    "criterion = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:06.828851Z",
     "iopub.status.busy": "2025-06-10T21:16:06.828582Z",
     "iopub.status.idle": "2025-06-10T21:16:06.833048Z",
     "shell.execute_reply": "2025-06-10T21:16:06.832278Z"
    }
   },
   "outputs": [],
   "source": [
    "second_mdp = md.DiscountedMDP(criterion, stateSpace, actionSpace, trans, rews, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Value\n",
    "\n",
    "[Back to Table of Contents](#table-of-contents)\n",
    "\n",
    "### Creation of the Q Value associated with a policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also possible to create a `FeedbackQvalueMDP` in a `DiscountedMDP`. A `FeedbackQvalueMDP` is an object that is created form the value of a policy (in our case a `FeedbackSolutionMDP`). It stores a *Q-value* for any couple *(s,a)* with *s* the state and *a* the action. From that, it is then possible to randomly draw actions according to the *EpsilonGreedy* or *Softmax* rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `FeedbackQvalueMDP` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:06.835226Z",
     "iopub.status.busy": "2025-06-10T21:16:06.834987Z",
     "iopub.status.idle": "2025-06-10T21:16:06.980790Z",
     "shell.execute_reply": "2025-06-10T21:16:06.979914Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimum2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m F = second_mdp.GetQValue(\u001b[43moptimum2\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'optimum2' is not defined"
     ]
    }
   ],
   "source": [
    "F = second_mdp.GetQValue(optimum2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:06.983396Z",
     "iopub.status.busy": "2025-06-10T21:16:06.982949Z",
     "iopub.status.idle": "2025-06-10T21:16:06.999210Z",
     "shell.execute_reply": "2025-06-10T21:16:06.998461Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mF\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For drawing action we should reset the random generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:07.001291Z",
     "iopub.status.busy": "2025-06-10T21:16:07.001082Z",
     "iopub.status.idle": "2025-06-10T21:16:07.016907Z",
     "shell.execute_reply": "2025-06-10T21:16:07.016171Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mF\u001b[49m.ResetSeed()\n",
      "\u001b[31mNameError\u001b[39m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "F.ResetSeed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We draw an action with *EpsilonGreedy* principle in state 0 with epsilon=0.1 for a maximisation criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:07.018739Z",
     "iopub.status.busy": "2025-06-10T21:16:07.018561Z",
     "iopub.status.idle": "2025-06-10T21:16:07.033032Z",
     "shell.execute_reply": "2025-06-10T21:16:07.032289Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m action = \u001b[43mF\u001b[49m.EpsilonGreedyMax(\u001b[32m0\u001b[39m, \u001b[32m0.1\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(action)\n",
      "\u001b[31mNameError\u001b[39m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "action = F.EpsilonGreedyMax(0, 0.1)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We draw an action with *SoftMax* principle in state 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T21:16:07.035171Z",
     "iopub.status.busy": "2025-06-10T21:16:07.034948Z",
     "iopub.status.idle": "2025-06-10T21:16:07.049946Z",
     "shell.execute_reply": "2025-06-10T21:16:07.049196Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m action = \u001b[43mF\u001b[49m.SoftMax(\u001b[32m2\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(action)\n",
      "\u001b[31mNameError\u001b[39m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "action = F.SoftMax(2)\n",
    "print(action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marmote-use",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
